{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e697d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24545b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show(tensor: torch.Tensor):\n",
    "    tensor = tensor.detach().squeeze().cpu()\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(tensor, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df56009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59faaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305de8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b72b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4c40bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896fc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e18d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160e1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 9, Actual: 2\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "out, target = next(iter(train_loader))\n",
    "out = out.to(device)\n",
    "target = target.to(device)\n",
    "predicted = net(out[0][0].flatten()).argmax()\n",
    "actual = target[0]\n",
    "print(f\"Predicted: {predicted}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65697933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optim_fn, training_data, test_data):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn()\n",
    "        self.optim = optim_fn(self.model.parameters(), lr=0.001)\n",
    "        self.training_data = training_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def train(self):\n",
    "        train_loader = DataLoader(self.training_data, batch_size=64, shuffle=True)\n",
    "\n",
    "        for data, targets in train_loader:\n",
    "            self.optim.zero_grad()\n",
    "\n",
    "            data = data.squeeze(1).flatten(1, 2)\n",
    "            data = data.to(device)\n",
    "            output = self.model(data)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            loss = self.loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optim.step()\n",
    "\n",
    "            correct = torch.sum(output.argmax(1) == targets).item()\n",
    "            total = output.size(0)\n",
    "\n",
    "            print(\n",
    "                f\"Training accuracy: {round((correct / total) * 100, 2)}\\tTraining loss: {loss.item()}\\n\"\n",
    "            )\n",
    "            print(\"\")\n",
    "\n",
    "    def validate(self):\n",
    "        test_loader = DataLoader(self.test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, targets in test_loader:\n",
    "            data = data.squeeze(1).flatten(1, 2)\n",
    "            data = data.to(device)\n",
    "\n",
    "            output = self.model(data)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            correct += torch.sum(output.argmax(1) == targets).item()\n",
    "            total += output.size(0)\n",
    "\n",
    "        print(f\"Validation accuracy: {round((correct / total) * 100, 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e3b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1..\n",
      "Training accuracy: 7.81\tTraining loss: 2.3201496601104736\n",
      "\n",
      "\n",
      "Training accuracy: 10.94\tTraining loss: 2.298546552658081\n",
      "\n",
      "\n",
      "Training accuracy: 17.19\tTraining loss: 2.2556025981903076\n",
      "\n",
      "\n",
      "Training accuracy: 31.25\tTraining loss: 2.2150981426239014\n",
      "\n",
      "\n",
      "Training accuracy: 40.62\tTraining loss: 2.2066333293914795\n",
      "\n",
      "\n",
      "Training accuracy: 46.88\tTraining loss: 2.1638400554656982\n",
      "\n",
      "\n",
      "Training accuracy: 60.94\tTraining loss: 2.1159136295318604\n",
      "\n",
      "\n",
      "Training accuracy: 59.38\tTraining loss: 2.11373233795166\n",
      "\n",
      "\n",
      "Training accuracy: 42.19\tTraining loss: 2.0821914672851562\n",
      "\n",
      "\n",
      "Training accuracy: 57.81\tTraining loss: 2.0177135467529297\n",
      "\n",
      "\n",
      "Training accuracy: 50.0\tTraining loss: 2.0125479698181152\n",
      "\n",
      "\n",
      "Training accuracy: 50.0\tTraining loss: 2.001892328262329\n",
      "\n",
      "\n",
      "Training accuracy: 51.56\tTraining loss: 1.9441895484924316\n",
      "\n",
      "\n",
      "Training accuracy: 51.56\tTraining loss: 1.957268238067627\n",
      "\n",
      "\n",
      "Training accuracy: 45.31\tTraining loss: 2.0038468837738037\n",
      "\n",
      "\n",
      "Training accuracy: 51.56\tTraining loss: 1.8958232402801514\n",
      "\n",
      "\n",
      "Training accuracy: 64.06\tTraining loss: 1.8222506046295166\n",
      "\n",
      "\n",
      "Training accuracy: 62.5\tTraining loss: 1.8174328804016113\n",
      "\n",
      "\n",
      "Training accuracy: 64.06\tTraining loss: 1.7172552347183228\n",
      "\n",
      "\n",
      "Training accuracy: 73.44\tTraining loss: 1.733220100402832\n",
      "\n",
      "\n",
      "Training accuracy: 73.44\tTraining loss: 1.633763313293457\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 1.5749857425689697\n",
      "\n",
      "\n",
      "Training accuracy: 71.88\tTraining loss: 1.5756906270980835\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 1.4935307502746582\n",
      "\n",
      "\n",
      "Training accuracy: 68.75\tTraining loss: 1.6272845268249512\n",
      "\n",
      "\n",
      "Training accuracy: 73.44\tTraining loss: 1.507455825805664\n",
      "\n",
      "\n",
      "Training accuracy: 65.62\tTraining loss: 1.5855423212051392\n",
      "\n",
      "\n",
      "Training accuracy: 67.19\tTraining loss: 1.549668312072754\n",
      "\n",
      "\n",
      "Training accuracy: 70.31\tTraining loss: 1.3736059665679932\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 1.3280552625656128\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 1.293389081954956\n",
      "\n",
      "\n",
      "Training accuracy: 67.19\tTraining loss: 1.3936951160430908\n",
      "\n",
      "\n",
      "Training accuracy: 70.31\tTraining loss: 1.352046012878418\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 1.2730778455734253\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 1.1930105686187744\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 1.2622841596603394\n",
      "\n",
      "\n",
      "Training accuracy: 70.31\tTraining loss: 1.2145864963531494\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 1.1179351806640625\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 1.20913827419281\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 1.0598084926605225\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 1.1062004566192627\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 1.0873035192489624\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 1.0528124570846558\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 1.02437424659729\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 1.04771089553833\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.9664391279220581\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 1.0448989868164062\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 0.9874610900878906\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.9320477843284607\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.8256055116653442\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.9453808069229126\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.8564771413803101\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.783939003944397\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.9015631675720215\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.8396155834197998\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.848236620426178\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.6319610476493835\n",
      "\n",
      "\n",
      "Training accuracy: 68.75\tTraining loss: 1.0076026916503906\n",
      "\n",
      "\n",
      "Training accuracy: 71.88\tTraining loss: 1.0011495351791382\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.7974026203155518\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.7914871573448181\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.7958823442459106\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.7988921403884888\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.6882288455963135\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 0.7234032154083252\n",
      "\n",
      "\n",
      "Training accuracy: 71.88\tTraining loss: 0.8898048996925354\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.7031498551368713\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.7182146310806274\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.519842267036438\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.6640639305114746\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 0.746636688709259\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.7356266975402832\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.6477009057998657\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.7416149377822876\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.6395325660705566\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.6272626519203186\n",
      "\n",
      "\n",
      "Training accuracy: 76.56\tTraining loss: 0.8165184259414673\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.7096084952354431\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.5947268009185791\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.4478754997253418\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.6519148349761963\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.6448869109153748\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.6801959276199341\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5882830023765564\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.6560314893722534\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5758374333381653\n",
      "\n",
      "\n",
      "Training accuracy: 79.69\tTraining loss: 0.668677806854248\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.46914780139923096\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.45827439427375793\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.6573604345321655\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5105440616607666\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.513419508934021\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5973896980285645\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.7105745077133179\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.554226815700531\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4591197371482849\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.35763102769851685\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.6926687359809875\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.6262975335121155\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.468445360660553\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.42475980520248413\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5825912952423096\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5245376825332642\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.6073926091194153\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.4810373783111572\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.598376989364624\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3926900625228882\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.46655750274658203\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5461004972457886\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5900403261184692\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.49960654973983765\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5789607763290405\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5992013216018677\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.40476277470588684\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4095289707183838\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4482450783252716\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.6358425617218018\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36826756596565247\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.44955945014953613\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5069454908370972\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.44025719165802\n",
      "\n",
      "\n",
      "Training accuracy: 78.12\tTraining loss: 0.7583150863647461\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3954424262046814\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5787250995635986\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.4328792095184326\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.6212868690490723\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5064526200294495\n",
      "\n",
      "\n",
      "Training accuracy: 73.44\tTraining loss: 0.8381096124649048\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.33513620495796204\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4079493582248688\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.27038151025772095\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.6523345708847046\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3733102083206177\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4658215641975403\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3398030400276184\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5660768747329712\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5114566087722778\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.301317036151886\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4465392529964447\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.44745615124702454\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4588490128517151\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.5272731781005859\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.38046935200691223\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3399154543876648\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.41893261671066284\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.5193622708320618\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3953035771846771\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4200325012207031\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.43397095799446106\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5265142917633057\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5873740911483765\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.366580069065094\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5072162747383118\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5668505430221558\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3559410870075226\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3687993884086609\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37519368529319763\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.42244279384613037\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.5607297420501709\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4442332684993744\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3758426308631897\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.38757479190826416\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.6326467990875244\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3359401822090149\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.4354546070098877\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4132586717605591\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3341902792453766\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.5249253511428833\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3556836247444153\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.36404991149902344\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.40195432305336\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3800984025001526\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3093920052051544\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4131871163845062\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.43952709436416626\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.408322274684906\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.40934425592422485\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33140066266059875\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.412150502204895\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3275865912437439\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27098584175109863\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4127214550971985\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.32819560170173645\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4052720069885254\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37503159046173096\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.44890809059143066\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.5190659165382385\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.37237226963043213\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.42712169885635376\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2575632333755493\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.5044434070587158\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3527911305427551\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24980738759040833\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4336732029914856\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23794128000736237\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2927142083644867\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4277428388595581\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27800339460372925\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4379541277885437\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3449552655220032\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4028928875923157\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.7026299238204956\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.41195160150527954\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.34965604543685913\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3192629814147949\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5483388900756836\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.36208376288414\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4810526669025421\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.48401519656181335\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3860934376716614\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2848013639450073\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3193492293357849\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29631543159484863\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2614802420139313\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.33977216482162476\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3844374418258667\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2554304897785187\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.43954113125801086\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2274317890405655\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3666623532772064\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3590853214263916\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.4430178701877594\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36439916491508484\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37689828872680664\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3707599639892578\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.42589813470840454\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4939601421356201\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.31494152545928955\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.38408294320106506\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21502789855003357\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.43346017599105835\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3676704168319702\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.40022194385528564\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2688452899456024\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3004838228225708\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.34223365783691406\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5073224306106567\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3384755849838257\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2277546525001526\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3357144296169281\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3481959104537964\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3443341851234436\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.35817980766296387\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3599160313606262\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2971803843975067\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.34524500370025635\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2861984074115753\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4231938421726227\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28658658266067505\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.36504143476486206\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.5590105652809143\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4206639230251312\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4099045395851135\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3287079334259033\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.5024994611740112\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.374869704246521\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.36524057388305664\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2573866844177246\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3680834174156189\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3545297384262085\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3934437930583954\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.35464662313461304\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3738615810871124\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.35590291023254395\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20885613560676575\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.38853177428245544\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3348623812198639\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.42957621812820435\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3694363236427307\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.5104749202728271\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.23482054471969604\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.253845751285553\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.49890318512916565\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29218506813049316\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25050485134124756\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2779032289981842\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36015892028808594\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5496917963027954\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2846195697784424\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3144683241844177\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2501254081726074\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4082116484642029\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36305272579193115\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32188865542411804\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3154405355453491\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.45935070514678955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11842992156744003\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17233705520629883\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37921473383903503\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36734896898269653\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3448355197906494\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3446401059627533\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33121341466903687\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4414098262786865\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3232530355453491\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20993724465370178\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.24626731872558594\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2952920198440552\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31640878319740295\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5470499992370605\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4681374430656433\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3628208339214325\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.43523305654525757\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20430988073349\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3662644624710083\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.3822941184043884\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.40779852867126465\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.333431601524353\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21142640709877014\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4262452721595764\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33181363344192505\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.26300859451293945\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.31661757826805115\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24137526750564575\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1798679530620575\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.4270118474960327\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29352080821990967\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27130287885665894\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.42266684770584106\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.4640722870826721\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2824937403202057\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3234289586544037\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.30116114020347595\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2406834065914154\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2155628502368927\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.222530797123909\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2788292169570923\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.34921449422836304\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3533253073692322\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5008143186569214\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21549195051193237\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28793177008628845\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2527737021446228\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28863954544067383\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3959270119667053\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.536114513874054\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4948590099811554\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32629698514938354\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24931403994560242\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14915844798088074\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.35223037004470825\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2733546495437622\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.37172743678092957\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.45124882459640503\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.46241918206214905\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2611558437347412\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.17743214964866638\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19054777920246124\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.43636831641197205\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21890807151794434\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2749097943305969\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.30905207991600037\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22024212777614594\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.472398042678833\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24225202202796936\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.36327970027923584\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14861202239990234\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.40162092447280884\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19759470224380493\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2421022355556488\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2457190454006195\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2954016327857971\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3267792761325836\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25561726093292236\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.4111848473548889\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2637447416782379\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36375734210014343\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32738882303237915\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.40183526277542114\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3449143171310425\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.32176363468170166\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2988044321537018\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.25875356793403625\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3098798990249634\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20966124534606934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13305506110191345\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36644381284713745\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2659851908683777\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.33553314208984375\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12994694709777832\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.44877904653549194\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.49886107444763184\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2672945559024811\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5401975512504578\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.41319501399993896\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3813202381134033\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25887927412986755\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2562253177165985\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23586773872375488\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17623838782310486\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2430327832698822\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1570262759923935\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23772746324539185\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1821683794260025\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13621678948402405\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23221886157989502\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28514909744262695\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3953709304332733\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5049766898155212\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2037467658519745\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.263051837682724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2268163412809372\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.34959831833839417\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4601533114910126\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3091275095939636\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.43832170963287354\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37743306159973145\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21662679314613342\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.357540488243103\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3209523558616638\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4082298278808594\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14680543541908264\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5567182302474976\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19426076114177704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15507645905017853\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36196404695510864\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.4037497341632843\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4655598998069763\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2859828770160675\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2371945083141327\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.34911030530929565\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.38909393548965454\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2832508087158203\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32371336221694946\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.31492966413497925\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.46127575635910034\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3191421627998352\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2827502489089966\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.286315381526947\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3099769651889801\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.3563593029975891\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.28875732421875\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2563922107219696\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.35949450731277466\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23329715430736542\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.39207881689071655\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3398650884628296\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17822213470935822\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.39408862590789795\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2967616021633148\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22142481803894043\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21610990166664124\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2833831310272217\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21524441242218018\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29174163937568665\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3049324154853821\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.34683889150619507\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5244145393371582\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2761794924736023\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2822911739349365\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3257593512535095\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23603284358978271\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.5233875513076782\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.6289016008377075\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2138441801071167\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.28388452529907227\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2732001543045044\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3075469732284546\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3074130713939667\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.29586729407310486\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17111614346504211\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3621365427970886\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.38028913736343384\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.49608445167541504\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24376872181892395\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24053767323493958\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.34358662366867065\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3165625333786011\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.37181198596954346\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.431247353553772\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2629702687263489\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2462947517633438\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.23710393905639648\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2164776623249054\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5134023427963257\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3637142479419708\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.37999796867370605\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3374081254005432\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.35022103786468506\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.318829745054245\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.5056187510490417\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3558773398399353\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22180891036987305\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17141979932785034\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2812574505805969\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22804415225982666\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2322021722793579\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23079821467399597\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.44524747133255005\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22959613800048828\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22022221982479095\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25220996141433716\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1762615293264389\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4562864899635315\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10403849184513092\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4130310118198395\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3311353325843811\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3598082661628723\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14599652588367462\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3542947471141815\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19100338220596313\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.226135715842247\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26706069707870483\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24562332034111023\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33651429414749146\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2953574061393738\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2699471116065979\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.39738816022872925\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2879483103752136\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3434336185455322\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4420004189014435\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24595850706100464\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.5494304895401001\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23564396798610687\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26913028955459595\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22515834867954254\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22368019819259644\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.232547327876091\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23019984364509583\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21008789539337158\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4719385504722595\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24707116186618805\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3139561414718628\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22298872470855713\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2564416527748108\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3644733428955078\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26446279883384705\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2204015552997589\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3232318162918091\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2521504759788513\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.30837997794151306\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28049707412719727\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21500809490680695\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.304730623960495\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3694092631340027\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18416114151477814\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19906334578990936\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23070231080055237\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.32732442021369934\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31229448318481445\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28699567914009094\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3785267472267151\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4624130129814148\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3165510296821594\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23893511295318604\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2059723138809204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17000272870063782\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.40026402473449707\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.35013145208358765\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2756827473640442\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4347906708717346\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18635064363479614\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3342113792896271\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.5219981670379639\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.530269205570221\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23220574855804443\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2431093454360962\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2948262393474579\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2973645031452179\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31837910413742065\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27202993631362915\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3633543848991394\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2841939926147461\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19402292370796204\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.48374709486961365\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26005443930625916\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3148159682750702\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24713319540023804\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2310095578432083\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23666785657405853\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.37164074182510376\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.22039078176021576\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.223634734749794\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23710691928863525\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27703624963760376\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19671779870986938\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3001149892807007\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21844078600406647\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22154521942138672\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.46566295623779297\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13815902173519135\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.40268415212631226\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.41689109802246094\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33130064606666565\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.30146753787994385\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.44006893038749695\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.30548447370529175\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3396386504173279\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.46216562390327454\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2283695936203003\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21338754892349243\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4989970028400421\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15007062256336212\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27483853697776794\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.12444251775741577\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1778099238872528\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14522455632686615\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17953810095787048\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.5847991704940796\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18576283752918243\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24757267534732819\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21398429572582245\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4530831277370453\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3171979784965515\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.33016863465309143\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3439066410064697\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1974009871482849\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3297615051269531\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19006383419036865\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.32291895151138306\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24718742072582245\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19397670030593872\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19750910997390747\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.41624122858047485\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1582140028476715\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29440492391586304\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28575706481933594\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13957534730434418\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.38479870557785034\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3078528940677643\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.49295496940612793\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3183593451976776\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2326350063085556\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.2667791247367859\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.388823926448822\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19090816378593445\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22286012768745422\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.44508546590805054\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24992342293262482\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3219224214553833\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1610814481973648\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18889178335666656\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18523186445236206\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2909104824066162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12401572614908218\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.338489294052124\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12976497411727905\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.29220259189605713\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27637961506843567\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15376445651054382\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12612730264663696\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3405408561229706\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.359088271856308\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.256555438041687\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24058520793914795\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1850455105304718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10073865950107574\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.33779993653297424\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21226173639297485\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4269280433654785\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2641739547252655\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.48601436614990234\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2360706329345703\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1832980513572693\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22369712591171265\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.37146344780921936\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2710890769958496\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4017251133918762\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21273738145828247\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21498358249664307\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19576402008533478\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23526979982852936\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.4289153218269348\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.3963444232940674\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27404648065567017\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.26878154277801514\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3114849627017975\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.35311228036880493\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21643748879432678\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.32342529296875\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.30184316635131836\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15961557626724243\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3709760904312134\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22136366367340088\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2696932852268219\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3660161793231964\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23194068670272827\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3316059112548828\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17951297760009766\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3274528384208679\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15404435992240906\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2981438636779785\n",
      "\n",
      "\n",
      "Training accuracy: 82.81\tTraining loss: 0.46793031692504883\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2940995693206787\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2843664288520813\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13159775733947754\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.161189466714859\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25739341974258423\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11544347554445267\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17233026027679443\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5610954761505127\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37624913454055786\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2516937553882599\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1674337387084961\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2220364212989807\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.33572643995285034\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25561702251434326\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18968705832958221\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.34982219338417053\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1369549036026001\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3826448917388916\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2320500612258911\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22883109748363495\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3367317020893097\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.26834985613822937\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4152882397174835\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32558366656303406\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1888602375984192\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11025092005729675\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21852944791316986\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16592130064964294\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16879412531852722\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.31290820240974426\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32949650287628174\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31302469968795776\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1257627308368683\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2166731059551239\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3904806971549988\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17431282997131348\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2284248173236847\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4325622320175171\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25085151195526123\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3492147922515869\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2451019287109375\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19676122069358826\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18222929537296295\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36767399311065674\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15226998925209045\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16529829800128937\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3693554401397705\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11624746024608612\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2907678186893463\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21072503924369812\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3785632252693176\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2441367655992508\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.265959769487381\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26525068283081055\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3408377766609192\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22888046503067017\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2946178615093231\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2448606938123703\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.25927627086639404\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.43920570611953735\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16460055112838745\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15897555649280548\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2683960795402527\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15238457918167114\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4965623915195465\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3242034316062927\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20019811391830444\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.5176273584365845\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.5268093347549438\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.25314635038375854\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26137831807136536\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2768600583076477\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.264752596616745\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.30512183904647827\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23457829654216766\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17308157682418823\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14780397713184357\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22389933466911316\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.33543717861175537\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.28175559639930725\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4339131712913513\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3267640471458435\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24543116986751556\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37400785088539124\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22615697979927063\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27394115924835205\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21864208579063416\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18403828144073486\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19229057431221008\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.285334050655365\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27174198627471924\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.308337926864624\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.254361093044281\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2062477320432663\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24900436401367188\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22787228226661682\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.382682740688324\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1299392729997635\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3129498362541199\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4714377522468567\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4064357280731201\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3492119312286377\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37891584634780884\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14103549718856812\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3005574941635132\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1611866056919098\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.361270934343338\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15545272827148438\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20497262477874756\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19183467328548431\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16721037030220032\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22471138834953308\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19553318619728088\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23938313126564026\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22657394409179688\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.324424147605896\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4877256751060486\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21254822611808777\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25079479813575745\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.34254857897758484\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22671888768672943\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15986990928649902\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2017180174589157\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15049250423908234\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.26593172550201416\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17575791478157043\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12034568190574646\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.420465886592865\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1788834035396576\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2114977240562439\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1962915062904358\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23077307641506195\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4207834005355835\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2602865397930145\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1797846555709839\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.312483549118042\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10346749424934387\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22408857941627502\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17811518907546997\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2250850647687912\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18816301226615906\n",
      "\n",
      "\n",
      "Training accuracy: 81.25\tTraining loss: 0.4475330710411072\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.142060324549675\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19241398572921753\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1403098702430725\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2641059458255768\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20044304430484772\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.32794705033302307\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16310620307922363\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20044350624084473\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25226470828056335\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2328181266784668\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2693764269351959\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.36241477727890015\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23211833834648132\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21403756737709045\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3112173080444336\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2473491132259369\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2448579967021942\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37383556365966797\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19487209618091583\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16372163593769073\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3930063247680664\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2859736979007721\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3902009129524231\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15136630833148956\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2678837478160858\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33459609746932983\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20797941088676453\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07494925707578659\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.551160454750061\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3116375207901001\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1811814308166504\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10781386494636536\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19254601001739502\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14719367027282715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08476771414279938\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1231839656829834\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22963190078735352\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.4087514877319336\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.39816591143608093\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21002301573753357\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25762060284614563\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.19162078201770782\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10706574469804764\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19691000878810883\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18093101680278778\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2923333942890167\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.31960350275039673\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.28356945514678955\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07795117795467377\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.33040839433670044\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1365126073360443\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.30415210127830505\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4787755608558655\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18771138787269592\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2161191999912262\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21819649636745453\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2062191218137741\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2641424238681793\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23906320333480835\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2092582732439041\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15583272278308868\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.24663378298282623\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1451602280139923\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.5773473381996155\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3842321038246155\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1901218593120575\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1848069578409195\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16603299975395203\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.42257440090179443\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3772802948951721\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.303927481174469\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3206724226474762\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23420915007591248\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22563782334327698\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19700826704502106\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13698969781398773\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2718779444694519\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14255431294441223\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24997758865356445\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.38385793566703796\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.31571388244628906\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14811289310455322\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1697925329208374\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1609739065170288\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3933044672012329\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18545398116111755\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.322131872177124\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2388191819190979\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14653918147087097\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.30386924743652344\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16798371076583862\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09506553411483765\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3128332495689392\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20898453891277313\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22383296489715576\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2705942988395691\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13524863123893738\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2544897794723511\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13069400191307068\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.167500302195549\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16642048954963684\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.34127724170684814\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17046505212783813\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2892575263977051\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22085168957710266\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27601343393325806\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24529582262039185\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15581297874450684\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15694138407707214\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17137092351913452\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29942718148231506\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.245965376496315\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15256690979003906\n",
      "\n",
      "\n",
      "Validation accuracy: 93.52\n",
      "\n",
      "\n",
      "Epoch 2..\n",
      "Training accuracy: 92.19\tTraining loss: 0.20488005876541138\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2553596794605255\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20336788892745972\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1512390822172165\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17991963028907776\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21605058014392853\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.33562153577804565\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17301303148269653\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1198526993393898\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16230268776416779\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.34018853306770325\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.1986762136220932\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27319055795669556\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2689789831638336\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.26729363203048706\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33547765016555786\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16450999677181244\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.2850668728351593\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2533833980560303\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17191070318222046\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3055717647075653\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10258619487285614\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17510193586349487\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20218220353126526\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18937063217163086\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.35258597135543823\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16322855651378632\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2448693811893463\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13441260159015656\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22872497141361237\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.27067893743515015\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12966060638427734\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27268123626708984\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3956317603588104\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11273650825023651\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19482876360416412\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2862609624862671\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1396317481994629\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20755982398986816\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19022206962108612\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11354849487543106\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.252403199672699\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.09724190831184387\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19713595509529114\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1890421360731125\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.28263533115386963\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13527940213680267\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14465934038162231\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.41559138894081116\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16604986786842346\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16158686578273773\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25678786635398865\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3210778832435608\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.177230566740036\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20081482827663422\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24532301723957062\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3907233476638794\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27182117104530334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1125103235244751\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20493599772453308\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11169694364070892\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22369609773159027\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16426154971122742\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20153683423995972\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26942333579063416\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26280656456947327\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22570917010307312\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24636700749397278\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.21932898461818695\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1772262156009674\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12724043428897858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07701049745082855\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18070167303085327\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25509926676750183\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.263680100440979\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3132901191711426\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17244456708431244\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.35985660552978516\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3634641766548157\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07987898588180542\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22311070561408997\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18596981465816498\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2106691598892212\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.40833210945129395\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2971263527870178\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.31834131479263306\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3841840624809265\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18888317048549652\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12041296064853668\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24672169983386993\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19861437380313873\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15784502029418945\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32838600873947144\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.26746633648872375\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11705291271209717\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14963310956954956\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25147849321365356\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13887527585029602\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11741816997528076\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09521506726741791\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.26320523023605347\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.39469707012176514\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19033947587013245\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25912201404571533\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17508040368556976\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1470988392829895\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22558711469173431\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2115599811077118\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3059375286102295\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27902752161026\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1314263641834259\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3049359619617462\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14426827430725098\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.31094497442245483\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18796545267105103\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19597187638282776\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17677050828933716\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12299518287181854\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2918378710746765\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09102556854486465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14964021742343903\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18363863229751587\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25159138441085815\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2585572600364685\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2823302745819092\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13542279601097107\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2576545476913452\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24572227895259857\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14754369854927063\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2924896776676178\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27586209774017334\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25375035405158997\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2832915484905243\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26736295223236084\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2642792761325836\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2789073586463928\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14767125248908997\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2357843518257141\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.149589404463768\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.30538856983184814\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12121492624282837\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11354589462280273\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15481022000312805\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11180266737937927\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1819535493850708\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11641041934490204\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.27498799562454224\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2749905586242676\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2624034881591797\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08474858105182648\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3711695671081543\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20301279425621033\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10926877707242966\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07664012908935547\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2671836018562317\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22083143889904022\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18250063061714172\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.261055588722229\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25010886788368225\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.34075045585632324\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11045502126216888\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08563879877328873\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22803744673728943\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16985447704792023\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24746757745742798\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15952065587043762\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21188519895076752\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1939990222454071\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21783943474292755\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.38295629620552063\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12175758183002472\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2359260618686676\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24432335793972015\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20971716940402985\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2756671905517578\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17299078404903412\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3140992820262909\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1839994639158249\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05922401696443558\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.41377365589141846\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15144528448581696\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2656414210796356\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15061281621456146\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18928083777427673\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22034952044487\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10775090754032135\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3127579391002655\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09310272336006165\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3398953676223755\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18575938045978546\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12278451770544052\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24173873662948608\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17163759469985962\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17591920495033264\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1539064198732376\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15883758664131165\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.31134194135665894\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14360028505325317\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3393762409687042\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3836504817008972\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18568994104862213\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.264487087726593\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2073545753955841\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24815693497657776\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18051743507385254\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2439538836479187\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19949036836624146\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13589444756507874\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1037476658821106\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.233566015958786\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12267345190048218\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09989653527736664\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16019286215305328\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17801779508590698\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15065410733222961\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18035268783569336\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24561762809753418\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25708550214767456\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23159542679786682\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1964915543794632\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06370007991790771\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14293625950813293\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1757904589176178\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17876598238945007\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18250620365142822\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.28000086545944214\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2012796252965927\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14802351593971252\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3349394202232361\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13737405836582184\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24178233742713928\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3305734395980835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11863458156585693\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11620460450649261\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.45741337537765503\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11603374779224396\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09785576909780502\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0958365797996521\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33933186531066895\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4369423985481262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08501884341239929\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19298532605171204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10428014397621155\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32156190276145935\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22767889499664307\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2437746673822403\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22010475397109985\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2019728720188141\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11714449524879456\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1766212284564972\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2045774906873703\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2286563515663147\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09956815838813782\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27949345111846924\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4486895799636841\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23711764812469482\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15936224162578583\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1387808918952942\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19991900026798248\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19556282460689545\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2432197630405426\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2453414499759674\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3133634626865387\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.33358243107795715\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.30096882581710815\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27567386627197266\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09715539962053299\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14706119894981384\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15093013644218445\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23177583515644073\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2519571781158447\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11580256372690201\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20815958082675934\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21237893402576447\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2976464033126831\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14175403118133545\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19805559515953064\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3842576742172241\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20018742978572845\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15972574055194855\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1863361895084381\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16486205160617828\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1747247725725174\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15098637342453003\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1412043571472168\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.26508766412734985\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06899860501289368\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1659402698278427\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23547063767910004\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1728031188249588\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07980170845985413\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2294767051935196\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23512327671051025\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2681325674057007\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12814757227897644\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20217058062553406\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0473058745265007\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3147801160812378\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3074251413345337\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13519662618637085\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12647703289985657\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15841588377952576\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16665416955947876\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37712135910987854\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25525325536727905\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1738581359386444\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29506444931030273\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07319590449333191\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07431310415267944\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2259257435798645\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24411489069461823\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2924190163612366\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10427704453468323\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32571765780448914\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.087003692984581\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15586674213409424\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14507567882537842\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19221773743629456\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14544227719306946\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1488879919052124\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18241249024868011\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32529765367507935\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2644846439361572\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23281218111515045\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2179068624973297\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33134007453918457\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20959660410881042\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11925773322582245\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2845521569252014\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2214321494102478\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15615637600421906\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26345735788345337\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07630681991577148\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.310532808303833\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2752676010131836\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09163419902324677\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11659084260463715\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19804462790489197\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1182553693652153\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3456447720527649\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19086626172065735\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13734722137451172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1818276345729828\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1480652093887329\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08827674388885498\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29670393466949463\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3020736575126648\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22521668672561646\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.24058344960212708\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1907975971698761\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2079211324453354\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13307595252990723\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29393255710601807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3004812002182007\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24772518873214722\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2864462435245514\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3033338189125061\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09105414152145386\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11677759140729904\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20507168769836426\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22390605509281158\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10642227530479431\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32281607389450073\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.28798413276672363\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19236499071121216\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11741475015878677\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3233371376991272\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22973324358463287\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15336239337921143\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.15332627296447754\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07099887728691101\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12089937925338745\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13243699073791504\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.6135488152503967\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1808030754327774\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3021506667137146\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09923778474330902\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2577618956565857\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3373439311981201\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13487236201763153\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2608221173286438\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13403470814228058\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3001931607723236\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4456299841403961\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0907917469739914\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3043834865093231\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04216308891773224\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1444840133190155\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1634555459022522\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21798935532569885\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1848202645778656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05770692974328995\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18460214138031006\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11817926168441772\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13658499717712402\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19596168398857117\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15145228803157806\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3338554799556732\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.31402894854545593\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.10798397660255432\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22564712166786194\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1929897665977478\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2804960608482361\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36731529235839844\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09188394248485565\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28707563877105713\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1381826102733612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09989197552204132\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33142566680908203\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16673487424850464\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19821381568908691\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17751596868038177\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15294191241264343\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20117631554603577\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14371246099472046\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1998169869184494\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18112576007843018\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1502590775489807\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22703519463539124\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21593961119651794\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2132001519203186\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18576112389564514\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13537107408046722\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08404556661844254\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0678442120552063\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1864418387413025\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.202106773853302\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.127376526594162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0632898360490799\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15489561855793\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20973116159439087\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36979591846466064\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24402253329753876\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1447862684726715\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14832408726215363\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15972541272640228\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2143062800168991\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24622878432273865\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15552514791488647\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.38819292187690735\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2538340985774994\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16032211482524872\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21564975380897522\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27937978506088257\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11297552287578583\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2648625075817108\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12921085953712463\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0480583980679512\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15066245198249817\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.4131079912185669\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12879014015197754\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2373526394367218\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31281813979148865\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.37595197558403015\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1546144187450409\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11193066835403442\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08884455263614655\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11152216792106628\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.41286203265190125\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.331727534532547\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2406977117061615\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13851216435432434\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20136362314224243\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2790885865688324\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1351044774055481\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2014418989419937\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08389227092266083\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.30558907985687256\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.25644785165786743\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27405279874801636\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04468494653701782\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15370795130729675\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1763736605644226\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08727936446666718\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.4124395251274109\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24094313383102417\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.34512805938720703\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2550312578678131\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14479997754096985\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3219766914844513\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.27396437525749207\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24262577295303345\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1758163720369339\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21053479611873627\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.32657063007354736\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13551759719848633\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3519556522369385\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2568311095237732\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33990976214408875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09700433909893036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10147233307361603\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1321474015712738\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.221820667386055\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13985002040863037\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.4531150460243225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08459468185901642\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20993848145008087\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.177333265542984\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21378594636917114\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22896471619606018\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.106725312769413\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06118764355778694\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.23831787705421448\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17649485170841217\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.393056184053421\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2851489782333374\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.23052442073822021\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13522975146770477\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2157604694366455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13977448642253876\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12588390707969666\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11145173013210297\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13946734368801117\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.26186808943748474\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2759222984313965\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19485878944396973\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29551321268081665\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13150814175605774\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11953555047512054\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08882591128349304\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1718132346868515\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21095409989356995\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20939671993255615\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24880513548851013\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13956071436405182\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11090295016765594\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15543891489505768\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1883048415184021\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16801495850086212\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12770837545394897\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15059350430965424\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2776646316051483\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.27386197447776794\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20726129412651062\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2252698689699173\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.18925301730632782\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15657317638397217\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16017596423625946\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13002946972846985\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1179705262184143\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.26508986949920654\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11851043999195099\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.22803013026714325\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14438511431217194\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05582059919834137\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13262531161308289\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11174869537353516\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20513707399368286\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.34641680121421814\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28618183732032776\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11585411429405212\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14849533140659332\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.38746392726898193\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.2685897946357727\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12804162502288818\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2136974036693573\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19442534446716309\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15946990251541138\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.25225740671157837\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2635594606399536\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24412566423416138\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23731648921966553\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2324981838464737\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19193890690803528\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15418872237205505\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13432364165782928\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22541546821594238\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1106800064444542\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0616309754550457\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2632652819156647\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2054772973060608\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2693003714084625\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2005261778831482\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21509233117103577\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24815937876701355\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.31150782108306885\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20757339894771576\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18855451047420502\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.061648234724998474\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2324349731206894\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14693981409072876\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08289764076471329\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2283751666545868\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2865806221961975\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18366071581840515\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13644173741340637\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0796978771686554\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2382059246301651\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21643155813217163\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.32596567273139954\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19125723838806152\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.31218162178993225\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23661506175994873\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3290327191352844\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17789104580879211\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032013148069381714\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2296757996082306\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13771218061447144\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22598081827163696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.12082895636558533\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.355387806892395\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17821438610553741\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10870148986577988\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18668684363365173\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2744066119194031\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0574309304356575\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13269996643066406\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1563762128353119\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09026151895523071\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13294954597949982\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2622663974761963\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05775177478790283\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12900690734386444\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12235871702432632\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.24101227521896362\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1445707529783249\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07656152546405792\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2168998122215271\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.138739675283432\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0825682282447815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1177697405219078\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2245427370071411\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26361387968063354\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16223114728927612\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.276322603225708\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17746864259243011\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2152749001979828\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24670010805130005\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3564028739929199\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18154415488243103\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22042056918144226\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26459866762161255\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14105768501758575\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11755172908306122\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1425846368074417\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3403761684894562\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08929522335529327\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12958821654319763\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2478778064250946\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1754906177520752\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1294064074754715\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20164360105991364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10443870723247528\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3010038435459137\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19317783415317535\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.10317836701869965\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16433171927928925\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.18739652633666992\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2466883510351181\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1737210750579834\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14670917391777039\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16807109117507935\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10656016319990158\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14119352400302887\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.296805202960968\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16097135841846466\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07211171835660934\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2242913842201233\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24478483200073242\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14186835289001465\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2299967110157013\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20045700669288635\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058673709630966187\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20277051627635956\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.24896997213363647\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08219127357006073\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09974576532840729\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1434229016304016\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3328138589859009\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16872890293598175\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19813856482505798\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17027410864830017\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12579604983329773\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.33712679147720337\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27651143074035645\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17470912635326385\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19025757908821106\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1875717043876648\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21843931078910828\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.30690833926200867\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24367791414260864\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16845393180847168\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2414902150630951\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.28641390800476074\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17742548882961273\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.09251613914966583\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15239103138446808\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07522621005773544\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17995727062225342\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13294929265975952\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.30068284273147583\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21992146968841553\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12238073348999023\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07586994767189026\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07168439030647278\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20218738913536072\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16827595233917236\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11990059167146683\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17468717694282532\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0566934309899807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18857665359973907\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1555820107460022\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07571283727884293\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2129519283771515\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07613331824541092\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04316818341612816\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07943116128444672\n",
      "\n",
      "\n",
      "Training accuracy: 84.38\tTraining loss: 0.48560336232185364\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09236083924770355\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3370550274848938\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06525803357362747\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2709352672100067\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.117320716381073\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10472756624221802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09565199911594391\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07124800235033035\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22763775289058685\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.32353919744491577\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.232036292552948\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24613013863563538\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21893823146820068\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1409275233745575\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15655028820037842\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04182634875178337\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1959143579006195\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10538487881422043\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24655404686927795\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16841472685337067\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13761752843856812\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10765881836414337\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13967399299144745\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1576557755470276\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16393214464187622\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15863972902297974\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20590826869010925\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12644803524017334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07028617709875107\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07645928859710693\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14757879078388214\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17213156819343567\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1744002252817154\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23085373640060425\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16356760263442993\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21309149265289307\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21562384068965912\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20498090982437134\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.36644601821899414\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12299903482198715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09242884069681168\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24653193354606628\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16169293224811554\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05881012976169586\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2284395396709442\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.28334420919418335\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.23829540610313416\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07545284926891327\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13933715224266052\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04943308234214783\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11536148190498352\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14627361297607422\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2046702653169632\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1752844750881195\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1573653519153595\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.146406352519989\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2879861295223236\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2627124786376953\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05643317103385925\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21050235629081726\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19445142149925232\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1426457017660141\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14522987604141235\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11619258671998978\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2483014464378357\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16312718391418457\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3451569080352783\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09135762602090836\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11900322139263153\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27643778920173645\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20606984198093414\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09267698228359222\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1689894199371338\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1197294294834137\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1988086998462677\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.39003804326057434\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21152150630950928\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11295118182897568\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.178440660238266\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2489020824432373\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1614713966846466\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20930397510528564\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19452224671840668\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23567548394203186\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3265460133552551\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3692931532859802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14207959175109863\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10157959908246994\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16378837823867798\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08939824998378754\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16007107496261597\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18043386936187744\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.35352057218551636\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22069275379180908\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22834649682044983\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05123763531446457\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23569780588150024\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20942319929599762\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15833134949207306\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053159989416599274\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08267559111118317\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1866966187953949\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23830091953277588\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11891259253025055\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11538839340209961\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2904928922653198\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15569105744361877\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15628626942634583\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2754092812538147\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2912598252296448\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12695175409317017\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26631447672843933\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10165001451969147\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19705986976623535\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18219000101089478\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18715056777000427\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15552610158920288\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2561076879501343\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11907024681568146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13338714838027954\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.28555813431739807\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2973242402076721\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13470777869224548\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1106242835521698\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.23573333024978638\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.09799081832170486\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16393160820007324\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07727596163749695\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.34517616033554077\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2924146056175232\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1057462990283966\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1744171679019928\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09725356101989746\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26231905817985535\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2169322371482849\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19354423880577087\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03978171944618225\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1949920654296875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09731200337409973\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10373843461275101\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07235893607139587\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19636741280555725\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14103788137435913\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0549616813659668\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06242949143052101\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1045101061463356\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08425602316856384\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21829840540885925\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19644388556480408\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.26369214057922363\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16145554184913635\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22070293128490448\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04662516340613365\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09050904214382172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12332890927791595\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17294400930404663\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14396977424621582\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11450141668319702\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2063523828983307\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2271067500114441\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19757342338562012\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12570276856422424\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08028087764978409\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12771663069725037\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3048432469367981\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11171400547027588\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23287007212638855\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.050235021859407425\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1802130937576294\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2903902232646942\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.17509710788726807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2947315275669098\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1371622532606125\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10353982448577881\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12980127334594727\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07572977989912033\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11344961076974869\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2324758768081665\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06495680660009384\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26917898654937744\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12648464739322662\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17844972014427185\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1487533301115036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14343678951263428\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2141229212284088\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12265925109386444\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23635759949684143\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.23941782116889954\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1396116316318512\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09541159123182297\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11223036795854568\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23044094443321228\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07982751727104187\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12173814326524734\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04796392470598221\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19384106993675232\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2562190890312195\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.22829124331474304\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11725351214408875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09597829729318619\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1506204903125763\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16376811265945435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058723218739032745\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14289185404777527\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26755571365356445\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.26158589124679565\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20735272765159607\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2280246913433075\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19119319319725037\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2069074958562851\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15833142399787903\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16107355058193207\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23195651173591614\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.5236404538154602\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08007597923278809\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26980677247047424\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12097765505313873\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12185229361057281\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2079009860754013\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15420496463775635\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14162097871303558\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1764131784439087\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04091169685125351\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11166705936193466\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07154328376054764\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25554752349853516\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14124341309070587\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09623979777097702\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1471397876739502\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24034026265144348\n",
      "\n",
      "\n",
      "Validation accuracy: 95.23\n",
      "\n",
      "\n",
      "Epoch 3..\n",
      "Training accuracy: 96.88\tTraining loss: 0.1973922848701477\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03502785414457321\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2535257339477539\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16152572631835938\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3578377664089203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08105230331420898\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06074521318078041\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2293367087841034\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12099063396453857\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.26387819647789\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08286616206169128\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16189387440681458\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.3719988465309143\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22093674540519714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07109708338975906\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11014920473098755\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19792643189430237\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10193890333175659\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15744630992412567\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15344740450382233\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1329762041568756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028036922216415405\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.3467252850532532\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15397849678993225\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05067015439271927\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15257126092910767\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13759347796440125\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18042798340320587\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0676976665854454\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11318060755729675\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04179861396551132\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07857315242290497\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3018200397491455\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06572660058736801\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1740821748971939\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32509997487068176\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18982136249542236\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2709851861000061\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24423465132713318\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12225888669490814\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2892029881477356\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17865435779094696\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09817163646221161\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13590756058692932\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061689864844083786\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09340085834264755\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12915509939193726\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09388944506645203\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11064333468675613\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05525700002908707\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12374851107597351\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11195705831050873\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08492591977119446\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17992770671844482\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0876624584197998\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18845675885677338\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11504635214805603\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13152256608009338\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.369753360748291\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0839783325791359\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15000176429748535\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07904208451509476\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.17983925342559814\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.27428391575813293\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2955765128135681\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11893387138843536\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.26403579115867615\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14117012917995453\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23279470205307007\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10267562419176102\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10385183244943619\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10681536793708801\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25448691844940186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09436149895191193\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08706094324588776\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15639200806617737\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2168629765510559\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11212942749261856\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1149866059422493\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10001428425312042\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23864610493183136\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.29304268956184387\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15384405851364136\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12967675924301147\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24011778831481934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10312321782112122\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22380006313323975\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16772954165935516\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18959753215312958\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.049207743257284164\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16767454147338867\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07252407819032669\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09579909592866898\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11324205249547958\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1399936079978943\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14122045040130615\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1786837875843048\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07623466849327087\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10737894475460052\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11782504618167877\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1291733980178833\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2645939588546753\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1877056062221527\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1425020694732666\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09155246615409851\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15621677041053772\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37098056077957153\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11685363948345184\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09860214591026306\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15635895729064941\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08075593411922455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1497143805027008\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10339031368494034\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09627416729927063\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17840136587619781\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08749502152204514\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2046816349029541\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07950154691934586\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.19677722454071045\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13759544491767883\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23545970022678375\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17705434560775757\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20894107222557068\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11624720692634583\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12771764397621155\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17920462787151337\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29446858167648315\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17195327579975128\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03235694766044617\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14874117076396942\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1215188056230545\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16003598272800446\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1804298460483551\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1332673728466034\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12499597668647766\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1662406325340271\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14358364045619965\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08602122962474823\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04578445851802826\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08970831334590912\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12271244823932648\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23750874400138855\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12190128862857819\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17387722432613373\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13632512092590332\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22333167493343353\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.348714679479599\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13329888880252838\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11130133271217346\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09754078835248947\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08293870091438293\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07494493573904037\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13649338483810425\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10413099825382233\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15199369192123413\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2039802521467209\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15733222663402557\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0670098140835762\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1649126559495926\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1293838918209076\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03784702718257904\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16794642806053162\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2473827600479126\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047531288117170334\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2124381959438324\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24092230200767517\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0626768171787262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08184882998466492\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1386348158121109\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07152451574802399\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07678893953561783\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13169892132282257\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.25643303990364075\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08758622407913208\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1804419457912445\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17038489878177643\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20858576893806458\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16332966089248657\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15980786085128784\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2087651491165161\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21468017995357513\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05234875902533531\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06127086654305458\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1472620815038681\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2847055196762085\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22138859331607819\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19489654898643494\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11925740540027618\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04331912845373154\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10400696843862534\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14400261640548706\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08893813192844391\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10330148786306381\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2098340392112732\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20656485855579376\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16627749800682068\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07225620746612549\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13415469229221344\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17535215616226196\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14211010932922363\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1323835253715515\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1300424337387085\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14575688540935516\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10200545191764832\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21542757749557495\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05006265640258789\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12161506712436676\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12314800918102264\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.35987594723701477\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3193475008010864\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18968194723129272\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23086807131767273\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04600425809621811\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12604324519634247\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09734831750392914\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25302550196647644\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14398106932640076\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11112627387046814\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09217295050621033\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3202524185180664\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16180771589279175\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08863038569688797\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08078835904598236\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14265885949134827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08130310475826263\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16944773495197296\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0782884731888771\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09565208107233047\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18122656643390656\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08109080791473389\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12360918521881104\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3163098096847534\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16184298694133759\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13243263959884644\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1390615850687027\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21735328435897827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.3133777678012848\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15606030821800232\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11794331669807434\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20980709791183472\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19306287169456482\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13403750956058502\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2612745761871338\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1702466607093811\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18641424179077148\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14222969114780426\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10043001174926758\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0905897319316864\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14685386419296265\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09874694049358368\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11779112368822098\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06444428116083145\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14079760015010834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07929832488298416\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22635477781295776\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24389034509658813\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16515704989433289\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.29901954531669617\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11360862106084824\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20278136432170868\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23235292732715607\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1352735012769699\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12294209003448486\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12572148442268372\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21443191170692444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09035898000001907\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18137353658676147\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06053933501243591\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16063663363456726\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.194986492395401\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09865964949131012\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22702717781066895\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05579981207847595\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07727623730897903\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08935293555259705\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07120053470134735\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1276686191558838\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3451986610889435\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1147228553891182\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09060396254062653\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21405011415481567\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17586976289749146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14440563321113586\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09620919078588486\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25277066230773926\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15026387572288513\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05760866776108742\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11560532450675964\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2884397506713867\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062189798802137375\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12877799570560455\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05771800875663757\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13934525847434998\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.3285607397556305\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0871795192360878\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16520172357559204\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14215697348117828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07233066856861115\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16063810884952545\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12023081630468369\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21786367893218994\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09688171744346619\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16358669102191925\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12451771646738052\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15092907845973969\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11550301313400269\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11133258044719696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04088959842920303\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23263728618621826\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25000622868537903\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1359575092792511\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.4863812029361725\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1555975079536438\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10159849375486374\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1925518810749054\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1450832039117813\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17242620885372162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0757182389497757\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12437492609024048\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15809272229671478\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048447031527757645\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11711812019348145\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06186548247933388\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1428568959236145\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0722338929772377\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07659919559955597\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1254642754793167\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19726905226707458\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1385887861251831\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12264968454837799\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25335872173309326\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2694752812385559\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.46186888217926025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1542462259531021\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06248965859413147\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1022624745965004\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09557975083589554\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11990654468536377\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13402515649795532\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08663147687911987\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26559484004974365\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11336639523506165\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15435896813869476\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22568872570991516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09395352751016617\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09706500172615051\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.09473349153995514\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08155116438865662\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2478228062391281\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16968761384487152\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17297804355621338\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0591500848531723\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24246731400489807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11114642024040222\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0920162945985794\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09608159959316254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08125915378332138\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12827515602111816\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25992023944854736\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07135652005672455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06528174132108688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04232778772711754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07723720371723175\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13254199922084808\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07989241927862167\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17681856453418732\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16131432354450226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08761021494865417\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.136508971452713\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19941100478172302\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23920227587223053\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11817765235900879\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.178243488073349\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09629984200000763\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13753093779087067\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17822635173797607\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20520499348640442\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1291845738887787\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.36087656021118164\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11430029571056366\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13650786876678467\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22691333293914795\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06130436062812805\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10678375512361526\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16945624351501465\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11165083944797516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18180394172668457\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2257947027683258\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12302127480506897\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16858498752117157\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18514499068260193\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07067625969648361\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1968228816986084\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3044116795063019\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15165261924266815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12419580668210983\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08531013131141663\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15519411861896515\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09871923923492432\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10624805092811584\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09676714241504669\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0856441929936409\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13790813088417053\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04760794714093208\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25240641832351685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1730821579694748\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.15239280462265015\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17288431525230408\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0826626792550087\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.33353179693222046\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07532879710197449\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17013055086135864\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07523684948682785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15886780619621277\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09147433936595917\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1154305636882782\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11842623353004456\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09346311539411545\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.237010195851326\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1751289814710617\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19402234256267548\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.09788548946380615\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14793434739112854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09536871314048767\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13381151854991913\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27513593435287476\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28878676891326904\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11780725419521332\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1611890345811844\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13729055225849152\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1775038242340088\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08022793382406235\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16434982419013977\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12191487848758698\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23242850601673126\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05522232502698898\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09818632900714874\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17739169299602509\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059250228106975555\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04919171333312988\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1156882792711258\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20862963795661926\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2425883561372757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06020079553127289\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18745629489421844\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14330822229385376\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.31134653091430664\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1481562703847885\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09675215184688568\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08690899610519409\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.127452552318573\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08664050698280334\n",
      "\n",
      "\n",
      "Training accuracy: 85.94\tTraining loss: 0.2610204815864563\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12180057913064957\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11157263815402985\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1573328673839569\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10232187807559967\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10453695058822632\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1270780712366104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10189786553382874\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09556358307600021\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1282082200050354\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045902714133262634\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05226907879114151\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10306598991155624\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12567323446273804\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08622940629720688\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3223819434642792\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1065954864025116\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15759477019309998\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2164149284362793\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07315713167190552\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19072197377681732\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0503523051738739\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2037992626428604\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17397528886795044\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1272331178188324\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3420373201370239\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13841547071933746\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15773098170757294\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16603145003318787\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14706109464168549\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1415352076292038\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06438468396663666\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.41159605979919434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12081126123666763\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08357623964548111\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12169401347637177\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2440732717514038\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0974554792046547\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16080565750598907\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07923752069473267\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13651470839977264\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0861157774925232\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17337243258953094\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17621028423309326\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13106781244277954\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.39174360036849976\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2867794334888458\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.25108855962753296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1083427295088768\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11697811633348465\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12444881349802017\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13911013305187225\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3520088195800781\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07731941342353821\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15630951523780823\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.27210935950279236\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23687244951725006\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.27076953649520874\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0998670905828476\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10551218688488007\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10692167282104492\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07982757687568665\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10035920143127441\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3203369379043579\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09447827190160751\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22089123725891113\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09379421174526215\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.31742343306541443\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.156175896525383\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06056078523397446\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06673817336559296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09416578710079193\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09337156265974045\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16930744051933289\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042160652577877045\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08181668817996979\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08477076888084412\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1032453328371048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03398614376783371\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08989287912845612\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2045937180519104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19221758842468262\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05888956040143967\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1405741423368454\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07058893144130707\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16955605149269104\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22089102864265442\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09430350363254547\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13837891817092896\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0894179493188858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08830752223730087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0599265992641449\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2012438327074051\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19046622514724731\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.20865923166275024\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13056550920009613\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10601868480443954\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09668603539466858\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24608232080936432\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2186196893453598\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14144250750541687\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07920962572097778\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058788001537323\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1309231072664261\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20826669037342072\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15304556488990784\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1436830759048462\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09811647236347198\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07843746244907379\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1289370059967041\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14483904838562012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1290445327758789\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1645599901676178\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15609166026115417\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07507535815238953\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1295444518327713\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08642974495887756\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12419193983078003\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15978430211544037\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0673668384552002\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07964964956045151\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1890532374382019\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17434880137443542\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21745912730693817\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06021565571427345\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.171042799949646\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10780920088291168\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2662884593009949\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.25225594639778137\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10680064558982849\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2631097733974457\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08626998960971832\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06646095216274261\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.163829043507576\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08284701406955719\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0520678386092186\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14759288728237152\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16518063843250275\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08111831545829773\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07047034800052643\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18408456444740295\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24842575192451477\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05396097153425217\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21337890625\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13005900382995605\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09915031492710114\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07285716384649277\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17285937070846558\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0989718809723854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08892975747585297\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13555213809013367\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14424201846122742\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.214292973279953\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15901866555213928\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25559860467910767\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09192224591970444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06552007794380188\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17073220014572144\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.17693780362606049\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05283895134925842\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0694466382265091\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0465678870677948\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.125539630651474\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19949345290660858\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22697722911834717\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08869262039661407\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06999143213033676\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13999275863170624\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1585521399974823\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15987470746040344\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04032732546329498\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13431459665298462\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11708638072013855\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1361849009990692\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15342631936073303\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2586386501789093\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11402967572212219\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13362841308116913\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14744877815246582\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11736419796943665\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07717160135507584\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06543093919754028\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.32148438692092896\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.179620623588562\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1437481939792633\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06665701419115067\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1639472246170044\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18032993376255035\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15448111295700073\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0982232466340065\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05517005920410156\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0819491446018219\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11754350364208221\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12478148192167282\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2504163682460785\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03949310630559921\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2698443830013275\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1049191802740097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07956504821777344\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13437068462371826\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21795837581157684\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21630185842514038\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3039373755455017\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1215105801820755\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07933010160923004\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21770896017551422\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21170569956302643\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1831205189228058\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1538168489933014\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.050049617886543274\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16816958785057068\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1762361228466034\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22948895394802094\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08016534894704819\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1480230987071991\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15195301175117493\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1128576397895813\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.37274134159088135\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1158883273601532\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14648324251174927\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09043790400028229\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06201320141553879\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09015068411827087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13280606269836426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045090463012456894\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.29911476373672485\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1939612627029419\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07934658229351044\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12109465897083282\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16235657036304474\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12363406270742416\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07325143367052078\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09112055599689484\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11389011144638062\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07319530099630356\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16943277418613434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06384731829166412\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.161896213889122\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12475564330816269\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.28683075308799744\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024526050314307213\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20599931478500366\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10322842746973038\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15066349506378174\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33878809213638306\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17448395490646362\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16003835201263428\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13557612895965576\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16459116339683533\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22297686338424683\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16223320364952087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11693867295980453\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1201476976275444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08028194308280945\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08266602456569672\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10601189732551575\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1689309924840927\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07519202679395676\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1269298493862152\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21793803572654724\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1873088926076889\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12231399118900299\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1422167271375656\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.29981327056884766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08592955023050308\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17430385947227478\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08525077253580093\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0925721749663353\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22922180593013763\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07931041717529297\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12050379067659378\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04298349842429161\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022362912073731422\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08986778557300568\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14333537220954895\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057093702256679535\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040704213082790375\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04971808195114136\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18311187624931335\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1518562287092209\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12341451644897461\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13263224065303802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09046382457017899\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1606069952249527\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.25762122869491577\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13786526024341583\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046541839838027954\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07228617370128632\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1517384946346283\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13633793592453003\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.168684184551239\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11479055881500244\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14831194281578064\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07325251400470734\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1321612298488617\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20563557744026184\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06849482655525208\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1671483814716339\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15455573797225952\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20322181284427643\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0829472541809082\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16602927446365356\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.30864039063453674\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11637455224990845\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054415687918663025\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09047845005989075\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1150636076927185\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3247119188308716\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.200265035033226\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1553730070590973\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10564572364091873\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10935366153717041\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07713297009468079\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07835918664932251\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14462034404277802\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07877353578805923\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07841430604457855\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.29135116934776306\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10410019755363464\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2108129858970642\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10840165615081787\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20726308226585388\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14083601534366608\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17485252022743225\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10929936170578003\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21119311451911926\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10159368067979813\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.183220773935318\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035017237067222595\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16383449733257294\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14903849363327026\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15660539269447327\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13377439975738525\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24895232915878296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07751530408859253\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07269146293401718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09448303282260895\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21983066201210022\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10665778815746307\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15128202736377716\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13451406359672546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07348374277353287\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06496811658143997\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2549535036087036\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15207567811012268\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19640198349952698\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15057061612606049\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07765191793441772\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10585100948810577\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02764926105737686\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20865464210510254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09317001700401306\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11144636571407318\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06223130598664284\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2377261519432068\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03920392692089081\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09610181301832199\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.044652655720710754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08206705749034882\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05330941081047058\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07364238798618317\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12430214881896973\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09484821557998657\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21571628749370575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10017192363739014\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2643216848373413\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19086158275604248\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16956955194473267\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05960722267627716\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22777770459651947\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08730985224246979\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0673254132270813\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0503414086997509\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09694401174783707\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17851562798023224\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057007744908332825\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07467465102672577\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1951076239347458\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08759762346744537\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16410568356513977\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09743745625019073\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11672021448612213\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0869002640247345\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2967863082885742\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04650266468524933\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12199972569942474\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13764886558055878\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07296642661094666\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1307617574930191\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18232649564743042\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12682519853115082\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15838129818439484\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.4505072832107544\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21831464767456055\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1473260521888733\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1307857632637024\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2750832736492157\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25647908449172974\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19480225443840027\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2599889636039734\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.227340966463089\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10965453088283539\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14612413942813873\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13769564032554626\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14024335145950317\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056872960180044174\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13093377649784088\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054992154240608215\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2232155203819275\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13749977946281433\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1496085226535797\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.17320361733436584\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06083191931247711\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11249883472919464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08032265305519104\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04154619947075844\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.2729663550853729\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11968666315078735\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08696542680263519\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16520589590072632\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06333979219198227\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1176837831735611\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09722989797592163\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13427795469760895\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09546172618865967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040904249995946884\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13192228972911835\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.253156453371048\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0645233690738678\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062523253262043\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09578146040439606\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07557842135429382\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06173202767968178\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18274366855621338\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1081325113773346\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04761180281639099\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11317436397075653\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12957412004470825\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15347474813461304\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17265522480010986\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16650161147117615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07752252370119095\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19529938697814941\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17769727110862732\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11195319890975952\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10043402761220932\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10178962349891663\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15914806723594666\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.27268198132514954\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0680592805147171\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05453742295503616\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11462201178073883\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13169631361961365\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1888425499200821\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11333274096250534\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2893097400665283\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07256460934877396\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14629347622394562\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09369591623544693\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1172051876783371\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10462725162506104\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1075611412525177\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06868979334831238\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.30977433919906616\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17234498262405396\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17317278683185577\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21332785487174988\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15346388518810272\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19476933777332306\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17038260400295258\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2048766165971756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05054169520735741\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05412960797548294\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24490168690681458\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1748596429824829\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0936104878783226\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1678040623664856\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1103576272726059\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1618858277797699\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04395556449890137\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03320782631635666\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12784624099731445\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05315858870744705\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1356993317604065\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1284765750169754\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.1823723018169403\n",
      "\n",
      "\n",
      "Validation accuracy: 96.14\n",
      "\n",
      "\n",
      "Epoch 4..\n",
      "Training accuracy: 96.88\tTraining loss: 0.07822766155004501\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1196163147687912\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19903185963630676\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025317803025245667\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08342370390892029\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10868906229734421\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08863738179206848\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044439710676670074\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2380223572254181\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1074296087026596\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047524966299533844\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3239213526248932\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11991515010595322\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10946249216794968\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13958358764648438\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06156519055366516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16075171530246735\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03793571889400482\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.11614575982093811\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.2167034149169922\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1105220690369606\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13507840037345886\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06515093892812729\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14558181166648865\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15213102102279663\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08868835121393204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08426901698112488\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1737602800130844\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0707867443561554\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08560019731521606\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12254568934440613\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15149261057376862\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14538565278053284\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07824209332466125\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06446096301078796\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12852627038955688\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10440490394830704\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057792019098997116\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07936809957027435\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13692352175712585\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1850319802761078\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07005705684423447\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11191390454769135\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20482978224754333\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14155234396457672\n",
      "\n",
      "\n",
      "Training accuracy: 87.5\tTraining loss: 0.2805699110031128\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1470317393541336\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11978612095117569\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2726658582687378\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2439093291759491\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18634817004203796\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08923016488552094\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06289906054735184\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.11050542443990707\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023166224360466003\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15896770358085632\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15000544488430023\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1146165281534195\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0725441724061966\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1023034006357193\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11045786738395691\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11918556690216064\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045551277697086334\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12378261238336563\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2387741506099701\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17477178573608398\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11260072141885757\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08349324762821198\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07291925698518753\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14048399031162262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05749564617872238\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05801127105951309\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17091749608516693\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06314826756715775\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07904964685440063\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1348034292459488\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10432704538106918\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08544307947158813\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.058652833104133606\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.21923868358135223\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03222672641277313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06242670863866806\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10451453924179077\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11268411576747894\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12271543592214584\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08489431440830231\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051618240773677826\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10993850976228714\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17844991385936737\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09521013498306274\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12055984139442444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05521594360470772\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20910915732383728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0655650943517685\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06285998225212097\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10253019630908966\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10522110760211945\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09906308352947235\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04062812775373459\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046078961342573166\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18879389762878418\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12857557833194733\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13125616312026978\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19018051028251648\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11553361266851425\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06618461012840271\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17636558413505554\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11616729199886322\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04913505166769028\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11826204508543015\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03927440196275711\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0884256437420845\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.13363435864448547\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10683637112379074\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13054320216178894\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15218445658683777\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21433788537979126\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28298476338386536\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05364995077252388\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15946367383003235\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09590071439743042\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10652799904346466\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13127946853637695\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11882063746452332\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09276530146598816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04655775800347328\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12247060239315033\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058237653225660324\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06289136409759521\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06285341829061508\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021573377773165703\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10080514848232269\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1763858199119568\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12312106788158417\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02868787944316864\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24152256548404694\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.25696802139282227\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1413518637418747\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20271989703178406\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1454043686389923\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1650652289390564\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11813049763441086\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17026680707931519\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08757037669420242\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13177725672721863\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0704929530620575\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08642023056745529\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0315626859664917\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12175174057483673\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10090101510286331\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1462167501449585\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0985652357339859\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11205686628818512\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1474284827709198\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18437425792217255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05949883162975311\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26017704606056213\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08967649191617966\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03532741591334343\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12720194458961487\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20163224637508392\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11319237947463989\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0655396431684494\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06674401462078094\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1608802080154419\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04843108355998993\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12986913323402405\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0836399644613266\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2307843714952469\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12859471142292023\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.33892425894737244\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2511600852012634\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0552622526884079\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17110830545425415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04111678898334503\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03386228159070015\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07517340034246445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05215545371174812\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05946864187717438\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04957202076911926\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08824383467435837\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16206768155097961\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07593809813261032\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09503795951604843\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10653400421142578\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18073499202728271\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09190434217453003\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04889426752924919\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12528666853904724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11243519186973572\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17980068922042847\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0779886394739151\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1699281632900238\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08603698015213013\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14319607615470886\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20314541459083557\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12037235498428345\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1002601832151413\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1387447565793991\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09571944177150726\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1413404494524002\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03869231045246124\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21826940774917603\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14983481168746948\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10218824446201324\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09012489020824432\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07212921977043152\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05835039168596268\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07540057599544525\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14822453260421753\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.067994624376297\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14444689452648163\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06028138846158981\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1754246950149536\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025589343160390854\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08232322335243225\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0815989077091217\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0407978892326355\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15497347712516785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08690421283245087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06532860547304153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05743591487407684\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1336822807788849\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1469656229019165\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03465874493122101\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05575436353683472\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05389059707522392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08713045716285706\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10451172292232513\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14148643612861633\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10473065078258514\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11819503456354141\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17303024232387543\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029589131474494934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16108788549900055\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09617085754871368\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11089170724153519\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06191452220082283\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07886791974306107\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13724875450134277\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3660357594490051\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033759117126464844\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08641623705625534\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14852827787399292\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05818047747015953\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15627580881118774\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07575011253356934\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14167363941669464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13020256161689758\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0366518571972847\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10241776704788208\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11424801498651505\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07331855595111847\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07448864728212357\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1904544234275818\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16861598193645477\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08632723242044449\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12249227613210678\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19222944974899292\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07566691190004349\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03700445964932442\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07698358595371246\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2969295382499695\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1491694450378418\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15182341635227203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06692484021186829\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09253928065299988\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0472501665353775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0649159848690033\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16694927215576172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12588101625442505\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05913674086332321\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05310850217938423\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1406708061695099\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13176247477531433\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20583415031433105\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11204282939434052\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03910136967897415\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.145307257771492\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1088380217552185\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034109096974134445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06804247200489044\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09405973553657532\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10880202054977417\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05328231677412987\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03653797134757042\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09856276214122772\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.24843381345272064\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14435698091983795\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24446362257003784\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1238141804933548\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23193421959877014\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15095637738704681\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08386337757110596\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09236778318881989\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0507112517952919\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1630973219871521\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14320041239261627\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10686016082763672\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2344486564397812\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08481434732675552\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040505919605493546\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028660301119089127\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1394360214471817\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22540637850761414\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14023205637931824\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1541985124349594\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062256935983896255\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0651760995388031\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03935970738530159\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09711790084838867\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16551858186721802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12320387363433838\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029811618849635124\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10731427371501923\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057755954563617706\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09118925780057907\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14788053929805756\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13474124670028687\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0853484570980072\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07709892094135284\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19579152762889862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09430521726608276\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02732785977423191\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0828215628862381\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14386703073978424\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04966665059328079\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12166328728199005\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21197077631950378\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.5296987891197205\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20058958232402802\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039738111197948456\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.26124128699302673\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09489329904317856\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15982025861740112\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14198826253414154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0453159362077713\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12503480911254883\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2113160640001297\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11428460478782654\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2330722212791443\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03038838505744934\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05653264746069908\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10354116559028625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016403883695602417\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05819997936487198\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2450738251209259\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09957555681467056\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.1989978551864624\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04907803609967232\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.047779206186532974\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0988951250910759\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10729660093784332\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0829978883266449\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022583987563848495\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08056133985519409\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11829420924186707\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06019502878189087\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1048542857170105\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15435221791267395\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14432580769062042\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.26704803109169006\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23801535367965698\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017443109303712845\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1686834841966629\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13806167244911194\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1698179692029953\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15316128730773926\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08885796368122101\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11764208972454071\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12107884138822556\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04603821784257889\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.28793346881866455\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09156264364719391\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1395789086818695\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.22513151168823242\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11243434250354767\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07400443404912949\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13140201568603516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11548765748739243\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22674545645713806\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11982680857181549\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11849208176136017\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21461303532123566\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12247303128242493\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08462440222501755\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1095443069934845\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06437726318836212\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11667674034833908\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04413970559835434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13474909961223602\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09370007365942001\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07024875283241272\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1456996500492096\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2732268273830414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.042419590055942535\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061578694730997086\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17836403846740723\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05599375069141388\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14677079021930695\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07698212563991547\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13912831246852875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06680019199848175\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19954541325569153\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1634591966867447\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10382159799337387\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1327352225780487\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10382518172264099\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19708827137947083\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029000863432884216\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08930327743291855\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1109447181224823\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08342618495225906\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08098037540912628\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19457441568374634\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16236397624015808\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21805377304553986\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18779250979423523\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07518905401229858\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22628408670425415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05684804916381836\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08294272422790527\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1372205913066864\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11486659944057465\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11242157220840454\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03542431443929672\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11743760108947754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061913635581731796\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19218747317790985\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06276220828294754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.20058079063892365\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17539355158805847\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10578258335590363\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.33543771505355835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07674476504325867\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3209018409252167\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07588805258274078\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19200709462165833\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05466929450631142\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23564103245735168\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06979019194841385\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18316850066184998\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11877978593111038\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12364070117473602\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04831153154373169\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13126739859580994\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09089182317256927\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08575904369354248\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32707566022872925\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1296030580997467\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1048688217997551\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07032257318496704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10848905891180038\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1263493001461029\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12069481611251831\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15533685684204102\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11355911940336227\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12797610461711884\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04138146713376045\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20993313193321228\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07973209023475647\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11940108239650726\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030659735202789307\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10577456653118134\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04493151977658272\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05169970169663429\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08856219798326492\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17951565980911255\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06041264533996582\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10224059224128723\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1381383091211319\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06227552145719528\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1947077214717865\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16906660795211792\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16988053917884827\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2306019365787506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09138795733451843\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23453029990196228\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10260464251041412\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12361466884613037\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07746454328298569\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1258096694946289\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05877554416656494\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15140940248966217\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1697567254304886\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1974675953388214\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09496112912893295\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11384010314941406\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11327482014894485\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1264590322971344\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12722322344779968\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09827089309692383\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1222059577703476\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1295643299818039\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07000060379505157\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23669442534446716\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1630885750055313\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03270481899380684\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06680382788181305\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12324801832437515\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05567079037427902\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1341911256313324\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09000030905008316\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09511908888816833\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15199624001979828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06433180719614029\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13767513632774353\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21928010880947113\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03377413749694824\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1768430471420288\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1558322310447693\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08505292236804962\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07517687231302261\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07394099235534668\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12380543351173401\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12217650562524796\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2668118476867676\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09184710681438446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06213197112083435\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03915085643529892\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049987804144620895\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020315438508987427\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10816215723752975\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.24293574690818787\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1323295533657074\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12146489322185516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14066185057163239\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1842345893383026\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14933130145072937\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1392776072025299\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06199798732995987\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.1855269819498062\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.069146528840065\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1226218119263649\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12197541445493698\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10933265089988708\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11373012512922287\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12710967659950256\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09722726792097092\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022910311818122864\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06347091495990753\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12126357853412628\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2567431926727295\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14242517948150635\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16027182340621948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051846325397491455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09839492291212082\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1452338695526123\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09122113883495331\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15957334637641907\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07909957319498062\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22271466255187988\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3109060823917389\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052933819591999054\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.230604350566864\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0639410987496376\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09120327979326248\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16595062613487244\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03231542184948921\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.33612990379333496\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1137607991695404\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04558819159865379\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10318490862846375\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1181824654340744\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058234311640262604\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07712070643901825\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06803148239850998\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.18276160955429077\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08206048607826233\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12974944710731506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08962354063987732\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07020501047372818\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1055559292435646\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19422441720962524\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06461311876773834\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04461648687720299\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08182064443826675\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054553210735321045\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043019942939281464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11065853387117386\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08693026751279831\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10794312506914139\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18184030055999756\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0641888827085495\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18978771567344666\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23604193329811096\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09078027307987213\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12643226981163025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09076906740665436\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06494290381669998\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2184717059135437\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.128449484705925\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3352227210998535\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04450022429227829\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07654482126235962\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06848568469285965\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1352069079875946\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07393990457057953\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12594588100910187\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07273298501968384\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07025927305221558\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09886226803064346\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07117214053869247\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07973451912403107\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2696327567100525\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08285823464393616\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04358334466814995\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05923740565776825\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16460047662258148\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1069277673959732\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22747871279716492\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10317148268222809\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0857747495174408\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13328386843204498\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.29591354727745056\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05277673155069351\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0890330970287323\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07753996551036835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062477272003889084\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11300712823867798\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03995029628276825\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.049726203083992004\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10614173114299774\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13834203779697418\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1855119913816452\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09019041061401367\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12084263563156128\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13412046432495117\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19165077805519104\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1265329271554947\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09028825908899307\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11679378896951675\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2144818753004074\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07045147567987442\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061945077031850815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06476190686225891\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.047278836369514465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04574553668498993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15131253004074097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09314469248056412\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02682393416762352\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1488853096961975\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18159230053424835\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09972081333398819\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0570359081029892\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11627638339996338\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09858150780200958\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08172300457954407\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17398661375045776\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.051802508533000946\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06016187369823456\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.044152215123176575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0773242861032486\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056157760322093964\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2438199520111084\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16801562905311584\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06939126551151276\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06263527274131775\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031176945194602013\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02285991609096527\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15248587727546692\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10775766521692276\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09331824630498886\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1208338588476181\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08691901713609695\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10029826313257217\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05388319492340088\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20647987723350525\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06380859017372131\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08197997510433197\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06534507870674133\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07809314876794815\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15968167781829834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11878222227096558\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07481476664543152\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15875545144081116\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08385886996984482\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1231420487165451\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04855683818459511\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10627691447734833\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09124034643173218\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07723493874073029\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11956264823675156\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03352915868163109\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05783752351999283\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09945157915353775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1191096305847168\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03484680876135826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032379671931266785\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08351863920688629\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09275118261575699\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15871526300907135\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043803006410598755\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12681955099105835\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038328759372234344\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10283038020133972\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11391741037368774\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10753441601991653\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16649000346660614\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09563252329826355\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11372917890548706\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07996801286935806\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.29997149109840393\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032958194613456726\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1545225977897644\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18292014300823212\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20976875722408295\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14011219143867493\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08234187960624695\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11372589319944382\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09547928720712662\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07593675702810287\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2255142629146576\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.13804683089256287\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14161048829555511\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23383910953998566\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1143757775425911\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10610619187355042\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1242055743932724\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14473332464694977\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08086727559566498\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06826689839363098\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18721622228622437\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015718037262558937\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08889708667993546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10606864839792252\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14274585247039795\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12017988413572311\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12970225512981415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06031554192304611\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04169141873717308\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1725684106349945\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3707134425640106\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03133748844265938\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14650531113147736\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13798809051513672\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2010754644870758\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1512432098388672\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12611739337444305\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11504312604665756\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08668401837348938\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10000550746917725\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2474299967288971\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04416051506996155\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13072851300239563\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08807265758514404\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08555993437767029\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05472506582736969\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06309273093938828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07940205931663513\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2075442224740982\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11263073980808258\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12410184741020203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0881178230047226\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19590605795383453\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04886390268802643\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11988120526075363\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13405415415763855\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16459159553050995\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06712517142295837\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.44472989439964294\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14064334332942963\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11762288212776184\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04298938065767288\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029877234250307083\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11324143409729004\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06525760889053345\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08454647660255432\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08598465472459793\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11298845708370209\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12173990160226822\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03733794391155243\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07028624415397644\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1197434514760971\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03172065690159798\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1105937510728836\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11482410877943039\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06910888850688934\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15557308495044708\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06903740763664246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03250408172607422\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08298926055431366\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054732684046030045\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1674758493900299\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13178661465644836\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1487111747264862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08715604245662689\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09110712260007858\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20109644532203674\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15389704704284668\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09552282840013504\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04897621273994446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04323495924472809\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19501736760139465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03853871300816536\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02530229091644287\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1954255998134613\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07398369908332825\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11616133153438568\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16559800505638123\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25196853280067444\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10083373636007309\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12158404290676117\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05668778717517853\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08791781961917877\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07127304375171661\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09423084557056427\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15011335909366608\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11078430712223053\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043697863817214966\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06331281363964081\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12490770220756531\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11190646886825562\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14120951294898987\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14187146723270416\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11617623269557953\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1664855182170868\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08367294073104858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1775587946176529\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056236449629068375\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15831103920936584\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05229218304157257\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1538512408733368\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18728205561637878\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04995973780751228\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2193010151386261\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17299729585647583\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08012042939662933\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2845652401447296\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13335655629634857\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1961778849363327\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09732469916343689\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13035239279270172\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07772103697061539\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07505730539560318\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10053739696741104\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13138671219348907\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15257050096988678\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1608966886997223\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12457533925771713\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18263885378837585\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16213132441043854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07489314675331116\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.23369626700878143\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10773208737373352\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12241975963115692\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025809619575738907\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0673053041100502\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04329331964254379\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06361673772335052\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07563729584217072\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.048780061304569244\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15182293951511383\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02059115469455719\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3051494359970093\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08882221579551697\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034067992120981216\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0834314376115799\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16614371538162231\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07729444652795792\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04856031760573387\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07768777012825012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0642310157418251\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0982922911643982\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16370749473571777\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1850092113018036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12451961636543274\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036706484854221344\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11477027833461761\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050044286996126175\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16221940517425537\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15809959173202515\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22260749340057373\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16545027494430542\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1515522599220276\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04491772502660751\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034854624420404434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08186274766921997\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14685681462287903\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035954900085926056\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.08401162177324295\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05246013030409813\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16993865370750427\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11867621541023254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057632431387901306\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13895218074321747\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20543721318244934\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1547895222902298\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17818264663219452\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0963108241558075\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0724615529179573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09296039491891861\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08457297831773758\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07259207963943481\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1799890697002411\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14142364263534546\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03979052975773811\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05516572296619415\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18787720799446106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07818662375211716\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04523178189992905\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035327062010765076\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04167921096086502\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12382858991622925\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17564444243907928\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07544383406639099\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10294608771800995\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1104922816157341\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13229000568389893\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16819871962070465\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12747733294963837\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23839373886585236\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04929468035697937\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25745877623558044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06687456369400024\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11440014094114304\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14031116664409637\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04800012335181236\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05429767072200775\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.042203258723020554\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0792224258184433\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06361696124076843\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028287243098020554\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18177028000354767\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16262058913707733\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3317550718784332\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06146228685975075\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0670108050107956\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18160824477672577\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05232333764433861\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1930813044309616\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14967598021030426\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13032442331314087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05390128493309021\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14920416474342346\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0868072509765625\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11202152073383331\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.062329597771167755\n",
      "\n",
      "\n",
      "Validation accuracy: 96.4\n",
      "\n",
      "\n",
      "Epoch 5..\n",
      "Training accuracy: 98.44\tTraining loss: 0.09467673301696777\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05210582911968231\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09836320579051971\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08806943148374557\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13396279513835907\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025762028992176056\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09162022918462753\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07358559221029282\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08658111840486526\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.29025155305862427\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1095360517501831\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03686961531639099\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1688452661037445\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.101212278008461\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1796518862247467\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07665915042161942\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052085720002651215\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06708341091871262\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13844619691371918\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12219315022230148\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18412236869335175\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11585111916065216\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07820353657007217\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2968292534351349\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11968401819467545\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1793307512998581\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0976603776216507\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10454827547073364\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10830599069595337\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1077212244272232\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19727769494056702\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13687415421009064\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04818970337510109\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1367589831352234\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09105664491653442\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03231867402791977\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09926549345254898\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14270254969596863\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11405453830957413\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15441812574863434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07698959112167358\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033383406698703766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0937490165233612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09587711095809937\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08575590699911118\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16797776520252228\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0939788743853569\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03457028046250343\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11009956896305084\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04877140000462532\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14656022191047668\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14247730374336243\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1246720403432846\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036757465451955795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047847453504800797\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11562953144311905\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09351690113544464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1315704733133316\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09028816223144531\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04415849596261978\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06501390039920807\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09616366773843765\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0565679557621479\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10808901488780975\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07498215138912201\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12371872365474701\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08795642852783203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04104624688625336\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10514805465936661\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16087985038757324\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.237039715051651\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2561972737312317\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07291445136070251\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06365957856178284\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3799629211425781\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14464199542999268\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04973341152071953\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03097309172153473\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08077162504196167\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054613418877124786\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06546424329280853\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11424878239631653\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043127696961164474\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06298650801181793\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05823379382491112\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08935238420963287\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.152375727891922\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06881272047758102\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0540844202041626\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03928652033209801\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1277473270893097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07339523732662201\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1040084958076477\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09317462146282196\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04338771849870682\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08940045535564423\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07618486881256104\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08840629458427429\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08272954821586609\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0670965313911438\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0716257318854332\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035799089819192886\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11419808864593506\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10642040520906448\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03195329010486603\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03676906228065491\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04348749667406082\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10834605246782303\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15790235996246338\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059712186455726624\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030284030362963676\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02840534597635269\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.080870121717453\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12448050826787949\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04567522928118706\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09927912801504135\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08999858051538467\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03615215793251991\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15429604053497314\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07203219830989838\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16156554222106934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15302753448486328\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03383314609527588\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05911317095160484\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10765278339385986\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0937253013253212\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15740320086479187\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1062975823879242\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0218963623046875\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09317131340503693\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2506730258464813\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03202243894338608\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10464455932378769\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1443307101726532\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.050207506865262985\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10173629224300385\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07962290942668915\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018884005025029182\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050079405307769775\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03507765755057335\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08342835307121277\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1387513428926468\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08883984386920929\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06928987801074982\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.127691388130188\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20918987691402435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06355566531419754\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09548178315162659\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03687593340873718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061953332275152206\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08690004050731659\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07856979966163635\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08182526379823685\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11149220168590546\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10712739080190659\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04585758596658707\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09306133538484573\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2614463269710541\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07491445541381836\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.256226122379303\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2606278657913208\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03947043418884277\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10030341893434525\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0676514059305191\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04078130051493645\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21599449217319489\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19969519972801208\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.08968019485473633\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11196604371070862\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07845479995012283\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13110928237438202\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1602281928062439\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07379912585020065\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14960654079914093\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.054000429809093475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02704394981265068\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05725065618753433\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09326333552598953\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14667627215385437\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10073016583919525\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03401269018650055\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11884155124425888\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02781185694038868\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11980612576007843\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.048185572028160095\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07664130628108978\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11455924808979034\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09832552075386047\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18223562836647034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08248261362314224\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11643116921186447\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11934392899274826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038166288286447525\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08317671716213226\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027454065158963203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02603299356997013\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09982886910438538\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0763285756111145\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11960884928703308\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07698793709278107\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12453082203865051\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22785161435604095\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.058821938931941986\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2544344961643219\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06093763932585716\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056323014199733734\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05801279842853546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10955353081226349\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036304373294115067\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09336602687835693\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1587602198123932\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05514658987522125\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05441173166036606\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044900454580783844\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02514813095331192\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06353811919689178\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07028825581073761\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.041940171271562576\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07866686582565308\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11183390766382217\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10164544731378555\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02700786478817463\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015857812017202377\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15710321068763733\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062323879450559616\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10415256023406982\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03925134986639023\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06822645664215088\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03174913674592972\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.365978479385376\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13178257644176483\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.039611026644706726\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06003417447209358\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13252872228622437\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08060136437416077\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028874052688479424\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06351872533559799\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15750445425510406\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1977805495262146\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07640714198350906\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05502551421523094\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13741789758205414\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10065419971942902\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08183102309703827\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11959484219551086\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08793024718761444\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17076608538627625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06612280756235123\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20331867039203644\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05092957615852356\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13237427175045013\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08407537639141083\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14542049169540405\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15654797852039337\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0587063767015934\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047595616430044174\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041228823363780975\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027970828115940094\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1535784900188446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0751083493232727\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06525520235300064\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09543989598751068\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1025010272860527\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09433779120445251\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21890783309936523\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07380752265453339\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08470937609672546\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10242527723312378\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07380525767803192\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1250927448272705\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13222888112068176\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1481718122959137\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04647524654865265\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3847193717956543\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06080734357237816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10189653933048248\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14318960905075073\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047442760318517685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07389317452907562\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17236393690109253\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04216183349490166\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10567305982112885\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03575175628066063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06323157250881195\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05763038247823715\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0887346863746643\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1684507429599762\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05717835947871208\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2627418637275696\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06950438022613525\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19427847862243652\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12628334760665894\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16596564650535583\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12038914114236832\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17738935351371765\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13554376363754272\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07127368450164795\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11154156923294067\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09599990397691727\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060656655579805374\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1308915764093399\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10559879243373871\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05014299228787422\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018610792234539986\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11267440021038055\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09104005992412567\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015788139775395393\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04902639240026474\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.28606757521629333\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1434258669614792\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04676196351647377\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13884347677230835\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1215270459651947\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03143379092216492\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04920095577836037\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03208763152360916\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17553676664829254\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06627002358436584\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04239792004227638\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23932361602783203\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22440752387046814\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20736218988895416\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.18533602356910706\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1521403044462204\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034836892038583755\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1342095583677292\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04546903073787689\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09021276235580444\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1973714530467987\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07761195302009583\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05692404508590698\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09494800865650177\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0718117207288742\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07698890566825867\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.26681894063949585\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1407550573348999\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.044983550906181335\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.049127623438835144\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09173281490802765\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.3119843006134033\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17541749775409698\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04790933057665825\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05821182206273079\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1357903629541397\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031097497791051865\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033706746995449066\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08415112644433975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0989990383386612\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18886159360408783\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1455489695072174\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048046983778476715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07733997702598572\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22376649081707\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04415598884224892\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07000426948070526\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03221772611141205\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08694656938314438\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07669636607170105\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13778002560138702\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09881098568439484\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07450029999017715\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10945449024438858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03363356739282608\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06337013840675354\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03719465807080269\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044880494475364685\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08043139427900314\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07790473103523254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0723053365945816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0995209813117981\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025238852947950363\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05697925388813019\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04189968481659889\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14312802255153656\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20509633421897888\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3195895552635193\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07782911509275436\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07458799332380295\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03199885040521622\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02308589592576027\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09810034185647964\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05343339219689369\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.19527538120746613\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11364936828613281\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09336883574724197\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06588555127382278\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09044171124696732\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2694515585899353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.039690226316452026\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10163771361112595\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08156526833772659\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12207567691802979\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1039576306939125\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06243228167295456\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18752777576446533\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14640650153160095\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07417890429496765\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05385764688253403\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10160832852125168\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2520707845687866\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11717328429222107\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06402209401130676\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05620588734745979\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0901433452963829\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04811973124742508\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056477271020412445\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11040976643562317\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04318739473819733\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11979539692401886\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015114909037947655\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21138328313827515\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10201283544301987\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17379844188690186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03997108340263367\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1023177057504654\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16282977163791656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03203611820936203\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21378472447395325\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03509785607457161\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07835590839385986\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05451119691133499\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12834376096725464\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18240322172641754\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1554478257894516\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030699092894792557\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19771531224250793\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16680604219436646\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10761775076389313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12118491530418396\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10417434573173523\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06554850935935974\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12276600301265717\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05251739174127579\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08173038065433502\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030754700303077698\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057529252022504807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1165950745344162\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10248620063066483\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22668245434761047\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1465912014245987\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02606418915092945\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.27583885192871094\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09580589830875397\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08049184828996658\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05219262093305588\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12974920868873596\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030148349702358246\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03510727360844612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053492940962314606\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024763796478509903\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025554943829774857\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03716850280761719\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1539255976676941\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034643471240997314\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053755857050418854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043549712747335434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048221852630376816\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16749775409698486\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.039643462747335434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.041757795959711075\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10510268062353134\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07923177629709244\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06237218528985977\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07624185085296631\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14328749477863312\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12686267495155334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07369700074195862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05956496298313141\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1203300952911377\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15964451432228088\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1493125855922699\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09806612133979797\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07804004102945328\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05549764633178711\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0263653714209795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08240942656993866\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14651280641555786\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07932218909263611\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03635606914758682\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12577678263187408\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09587053209543228\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11280887573957443\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1272793710231781\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10586364567279816\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018157823011279106\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03480890020728111\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14247716963291168\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1425950527191162\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0382276251912117\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19255918264389038\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06770788133144379\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13005556166172028\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08802388608455658\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1421191692352295\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0819007083773613\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07497505843639374\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22076964378356934\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05609859898686409\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14183464646339417\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05088547244668007\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07486915588378906\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10353688895702362\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06668078899383545\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03946014493703842\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08811554312705994\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07515288144350052\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18393340706825256\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09857805073261261\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06119333207607269\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043182000517845154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06875520944595337\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025636572390794754\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09956733882427216\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10351628810167313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0845353975892067\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054257482290267944\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07733500003814697\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11098405718803406\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058431029319763184\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24138477444648743\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2149183601140976\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10518625378608704\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10426508635282516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11417967081069946\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10253942757844925\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052510425448417664\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02701001800596714\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18477533757686615\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014506742358207703\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1653289943933487\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08804331719875336\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13064351677894592\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04368557035923004\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044798292219638824\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1608588695526123\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20194342732429504\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09006036818027496\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11717018485069275\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1219819113612175\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05890493094921112\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12250324338674545\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06607335805892944\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07160670310258865\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09052674472332001\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10172015428543091\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.041160598397254944\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09264156222343445\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1396646499633789\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0949501246213913\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11873222887516022\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01488118153065443\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09584599733352661\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041396621614694595\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03344295918941498\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13014434278011322\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06523501873016357\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09213763475418091\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07905265688896179\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059668831527233124\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08806033432483673\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20265507698059082\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058879680931568146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06720651686191559\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1705940067768097\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.17651772499084473\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1682863086462021\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08110912889242172\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06587709486484528\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09523353725671768\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22152145206928253\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13454125821590424\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07555735111236572\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1419430375099182\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07849300652742386\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13371528685092926\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05999687314033508\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037498217076063156\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1786792278289795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0619489885866642\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10303274542093277\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24843564629554749\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03610999137163162\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10962902009487152\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08767881989479065\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10106199979782104\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18864044547080994\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021364443004131317\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14997845888137817\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07714439183473587\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0919938012957573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07962594926357269\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.039402641355991364\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11402192711830139\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06228071078658104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09464241564273834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05670198053121567\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09078539162874222\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06185286119580269\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17277711629867554\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05156031996011734\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07137424498796463\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12514162063598633\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05125250667333603\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03863081336021423\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05638295039534569\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01352191437035799\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08767654001712799\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11707927286624908\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12144297361373901\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.20182284712791443\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11225271970033646\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15390236675739288\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1005520224571228\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04655388742685318\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1451418399810791\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03131761774420738\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022529220208525658\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12122329324483871\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06728166341781616\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05844882130622864\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08310559391975403\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03450627624988556\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016006361693143845\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13130424916744232\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02192298322916031\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1229202002286911\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1625232994556427\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06865934282541275\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042398080229759216\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1155303493142128\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04395609349012375\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15674279630184174\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08777816593647003\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036877814680337906\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12653794884681702\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04482312500476837\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16193123161792755\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14759275317192078\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22154608368873596\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09949452430009842\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09538538008928299\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13648727536201477\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20484410226345062\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029865877702832222\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027690144255757332\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2494657337665558\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24389782547950745\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09630320966243744\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04720022901892662\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050425294786691666\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03484991192817688\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06063416227698326\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2288500815629959\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3150765895843506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061934974044561386\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1755252182483673\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.042151905596256256\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1335512399673462\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08870204538106918\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25786522030830383\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06568390130996704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09262441098690033\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12375393509864807\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05779896676540375\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04714213311672211\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029818233102560043\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19539445638656616\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04892037808895111\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14924591779708862\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10083137452602386\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08059340715408325\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1391509771347046\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026815980672836304\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12738804519176483\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07886627316474915\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06657116115093231\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06011158227920532\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.045040033757686615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09430037438869476\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037706900388002396\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033331118524074554\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059267111122608185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054780956357717514\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04111189767718315\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03841960430145264\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04069818556308746\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08285199105739594\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09752000123262405\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06864067912101746\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054095856845378876\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08324841409921646\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11265451461076736\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0429786816239357\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05301830172538757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03171180561184883\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02077784761786461\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04546258598566055\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15809452533721924\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10607978701591492\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06233229488134384\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11134299635887146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06486556679010391\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09329289942979813\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05404488742351532\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049308378249406815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1412031352519989\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0731620043516159\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18036293983459473\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03872761130332947\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12296231091022491\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022208482027053833\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13470083475112915\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09809001535177231\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2279055267572403\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08653688430786133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051499057561159134\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15236888825893402\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0526285320520401\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025576353073120117\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04489801451563835\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12287411838769913\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02000230923295021\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1304505467414856\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08172968029975891\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12877750396728516\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09843768179416656\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05192027613520622\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08613550662994385\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056265588849782944\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15553593635559082\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09083148092031479\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07392918318510056\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06937941908836365\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09294138848781586\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.3319677412509918\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11918338388204575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06446321308612823\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07133914530277252\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06919224560260773\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07300553470849991\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03127691522240639\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0687883049249649\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07188307493925095\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.07201879471540451\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15395672619342804\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09497874230146408\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09666857868432999\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05480698496103287\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09112602472305298\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019298968836665154\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04306942597031593\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04639064893126488\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03229736536741257\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07169415056705475\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.3541385531425476\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09845255315303802\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12470540404319763\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06587886065244675\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18830519914627075\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1841660737991333\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11984142661094666\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12673461437225342\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14428138732910156\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09691166877746582\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013283245265483856\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03424099087715149\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16616617143154144\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06217452511191368\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06548585742712021\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040379658341407776\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15960508584976196\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08689384162425995\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09959673136472702\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24745531380176544\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035046983510255814\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014860151335597038\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08818306773900986\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0467451810836792\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06429585814476013\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.13926631212234497\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18701951205730438\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11102788895368576\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055121079087257385\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20235398411750793\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13267184793949127\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0622439831495285\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09273333847522736\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12394700944423676\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09773159772157669\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03565036877989769\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08607760071754456\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09689497947692871\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1255943775177002\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05934418365359306\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15624654293060303\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06829757988452911\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02515712007880211\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10557916015386581\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04193888604640961\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12004679441452026\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.19733406603336334\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1539764702320099\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12109672278165817\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.074411541223526\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043150920420885086\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17091147601604462\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17228111624717712\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20025616884231567\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08610893040895462\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1487782895565033\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010829659178853035\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05651352182030678\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11610649526119232\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07382214814424515\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08430690318346024\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05785373970866203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04284815862774849\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11009284853935242\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1250351518392563\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07858268916606903\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08303225785493851\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017325088381767273\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056074123829603195\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057908862829208374\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13608196377754211\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055113621056079865\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.046129871159791946\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059629715979099274\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.23304064571857452\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1139276996254921\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09061935544013977\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2402454912662506\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.3552243709564209\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05065615475177765\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0905991792678833\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15944063663482666\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04931061714887619\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12683849036693573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09397836029529572\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07680131494998932\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0651460736989975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14801877737045288\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032366350293159485\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10879069566726685\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15988799929618835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08222499489784241\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08203289657831192\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14231662452220917\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16166755557060242\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10718291997909546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10975010693073273\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.105571448802948\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12335974723100662\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11987544596195221\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07781881839036942\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06964626908302307\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0315522775053978\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14528319239616394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03073684684932232\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06539509445428848\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06993778049945831\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03669239580631256\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0599888451397419\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01965482532978058\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05620338022708893\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23421096801757812\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07396166026592255\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056276094168424606\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07027459144592285\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07434774935245514\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11913947761058807\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02436107024550438\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11410515010356903\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03348657488822937\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1169089674949646\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05350513011217117\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044612545520067215\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05471530556678772\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06324248760938644\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03591514378786087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04903215169906616\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07568420469760895\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0992039144039154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11298773437738419\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09857708215713501\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.3803007900714874\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07097570598125458\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0480908639729023\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06672245264053345\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17892581224441528\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14375072717666626\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028218593448400497\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10891708731651306\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0713990181684494\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03974458575248718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09438983350992203\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09072673320770264\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08123254776000977\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029043322429060936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07444416731595993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05302312597632408\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03662075847387314\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21593432128429413\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24632646143436432\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06464850157499313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08546723425388336\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08126845955848694\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07085127383470535\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059468142688274384\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10488153994083405\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037197526544332504\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02061532437801361\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05595099553465843\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04575932398438454\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09031282365322113\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029725201427936554\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1098698228597641\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11374109238386154\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07485410571098328\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041690848767757416\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09758660197257996\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05968961864709854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05850464105606079\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09228287637233734\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047375068068504333\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08163069188594818\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05753025785088539\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07898484170436859\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.11351773142814636\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09309238940477371\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0631842091679573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10681642591953278\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16948774456977844\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02237507700920105\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13477525115013123\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08735188096761703\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08034276962280273\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023604176938533783\n",
      "\n",
      "\n",
      "Validation accuracy: 96.96\n",
      "\n",
      "\n",
      "Epoch 6..\n",
      "Training accuracy: 100.0\tTraining loss: 0.04083062708377838\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020991964265704155\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02417006716132164\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06345660984516144\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05304750055074692\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04052359610795975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039340779185295105\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0826173946261406\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0316738598048687\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09964042901992798\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08417026698589325\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09074970334768295\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04447969049215317\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06000739336013794\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16842079162597656\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015055472031235695\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17471259832382202\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13424932956695557\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047145113348960876\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061111435294151306\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04283563420176506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04883919283747673\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0689326748251915\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04597903788089752\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10921980440616608\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.071662038564682\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08478248119354248\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05043349787592888\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060272157192230225\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1486218273639679\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015234989114105701\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.136824831366539\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060477953404188156\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10645480453968048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03374448046088219\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024864496663212776\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020623262971639633\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043174341320991516\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06209855154156685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1432400643825531\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008417421951889992\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19136694073677063\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06543686985969543\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04913759231567383\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03042207658290863\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12652426958084106\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03491656482219696\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051169682294130325\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09392040222883224\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08186647295951843\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12341929227113724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12978129088878632\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036038629710674286\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036080434918403625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0361333042383194\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06060187146067619\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07067129015922546\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09710693359375\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11037611961364746\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.17958694696426392\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12491777539253235\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12285466492176056\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030351251363754272\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2048397809267044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052388548851013184\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06864720582962036\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2416020631790161\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1365625262260437\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07555656135082245\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07117480039596558\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13499052822589874\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05129200965166092\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05256304889917374\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0441804975271225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07436005771160126\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12649744749069214\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12940356135368347\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10869844257831573\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01924484223127365\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10755136609077454\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05050080269575119\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06517401337623596\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04507925361394882\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046479836106300354\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040702223777770996\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026166416704654694\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08921252191066742\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09593600034713745\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08269950747489929\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0460243821144104\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1037774533033371\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06304972618818283\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057588156312704086\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16676795482635498\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15042227506637573\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05300108343362808\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09780856966972351\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09546229988336563\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10826733708381653\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06279267370700836\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06249379366636276\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14860625565052032\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12841659784317017\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16842198371887207\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019618049263954163\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018504831939935684\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.104448102414608\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25873667001724243\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14804552495479584\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17573638260364532\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043343912810087204\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02550722286105156\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08852896094322205\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032161492854356766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.041598059237003326\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.047456294298172\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18924963474273682\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14072197675704956\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18604633212089539\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03614889830350876\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03826729580760002\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03802729398012161\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12818777561187744\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01558071468025446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040036991238594055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027877796441316605\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0678616464138031\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062019407749176025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0712861567735672\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07079674303531647\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08390828967094421\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09945807605981827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04811234772205353\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11309367418289185\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028832245618104935\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12049286812543869\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10779477655887604\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11712579429149628\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03783923760056496\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1220008134841919\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15581505000591278\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046105705201625824\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04386329650878906\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07756942510604858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05981465056538582\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05029231309890747\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06019878014922142\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04838898405432701\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11127378791570663\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01718841679394245\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0856960117816925\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04121928662061691\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05559833347797394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04971597343683243\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09476669132709503\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14809247851371765\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20996272563934326\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07774500548839569\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05199769139289856\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028279492631554604\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15553395450115204\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06978671997785568\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15306740999221802\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036346595734357834\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09287936240434647\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14108231663703918\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11465412378311157\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018592528998851776\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07525818049907684\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.046454593539237976\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09478132426738739\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14993348717689514\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05817362666130066\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057619281113147736\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040273115038871765\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06274281442165375\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19893525540828705\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08435186743736267\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015661653131246567\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03137564659118652\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03707553446292877\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08851248770952225\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057326868176460266\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048312537372112274\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06666958332061768\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013701041229069233\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04729614034295082\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14140091836452484\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03706130385398865\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0935591384768486\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1114327609539032\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12850284576416016\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08106382191181183\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027720952406525612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03266875818371773\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03583194315433502\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061425864696502686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17026738822460175\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0598522424697876\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03961927443742752\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0483456552028656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057506635785102844\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0362466499209404\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07303646951913834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08001865446567535\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0729060024023056\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05115634202957153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040982894599437714\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10682295262813568\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029548827558755875\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1519586741924286\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022061984986066818\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07224061340093613\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0874398797750473\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04595407843589783\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07575523108243942\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03629641979932785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09906055778265\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02607308328151703\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049453411251306534\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08478961139917374\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18501144647598267\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01850956119596958\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07606354355812073\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06939740478992462\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08813396841287613\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045054368674755096\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06555220484733582\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038065046072006226\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12115257978439331\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039324045181274414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021642601117491722\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1123577207326889\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11316488683223724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14968730509281158\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03784481808543205\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05425199493765831\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016529496759176254\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024090280756354332\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08914860337972641\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2414182424545288\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02826462686061859\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08092373609542847\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0739208310842514\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06261974573135376\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03412815183401108\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1305937021970749\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11361541599035263\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10295138508081436\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13682225346565247\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07041016221046448\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1223793625831604\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09499925374984741\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11687792837619781\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08230739086866379\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048219237476587296\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14443343877792358\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0517396405339241\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03472109138965607\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0843440517783165\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061892662197351456\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04173059016466141\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04129728674888611\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04803665354847908\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01629127375781536\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.086040198802948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07613583654165268\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15358290076255798\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2830508351325989\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22820720076560974\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09884227067232132\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06257160753011703\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05571320652961731\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12593437731266022\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05124662071466446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07986778020858765\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05539301782846451\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17140761017799377\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10152380913496017\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03920163959264755\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05891222134232521\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017365412786602974\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1167038232088089\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03290867805480957\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.037946660071611404\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050177201628685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03546492010354996\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025963084772229195\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1062236875295639\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15073832869529724\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043708741664886475\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13070091605186462\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15140435099601746\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03376111388206482\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07165831327438354\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09628981351852417\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13699886202812195\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09025473147630692\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019691789522767067\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1255020797252655\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03197775408625603\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1202784925699234\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16280727088451385\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05889711529016495\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03545374423265457\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055866412818431854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10409361124038696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03549860417842865\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053553976118564606\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04838758334517479\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07196169346570969\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030006298795342445\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06625313311815262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07372714579105377\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04622979089617729\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020971674472093582\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061527710407972336\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09708458185195923\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047505103051662445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022929824888706207\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08189070224761963\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035356272011995316\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055204905569553375\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.2748669683933258\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07317381352186203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019855104386806488\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20968255400657654\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07042554020881653\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09156867861747742\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03407171368598938\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10022249817848206\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040259890258312225\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07578670233488083\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07034476101398468\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07862893491983414\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10668216645717621\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13117888569831848\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1000441461801529\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20392881333827972\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08182172477245331\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07650899887084961\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06835100054740906\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1194133311510086\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052790142595767975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04997967183589935\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05316271260380745\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04369471222162247\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040559396147727966\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013735505752265453\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01985359564423561\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.261237770318985\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15716227889060974\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07253928482532501\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13963302969932556\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03419079631567001\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017092911526560783\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055420346558094025\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05026920512318611\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03948278725147247\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18874916434288025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08418494462966919\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11327660083770752\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10170347988605499\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031176766380667686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06445753574371338\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1835373044013977\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03126185014843941\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02572469413280487\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15949919819831848\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10682304203510284\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06755448132753372\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1941535919904709\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2415754348039627\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07152795791625977\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08411332219839096\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14009103178977966\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022410687059164047\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06626008450984955\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15622791647911072\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03564050793647766\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.048102058470249176\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08450193703174591\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036751821637153625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02423771284520626\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042129091918468475\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07918666303157806\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0591304749250412\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045727409422397614\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051204487681388855\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03236313909292221\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20057740807533264\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07918662577867508\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09002453088760376\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0920504480600357\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033679597079753876\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11118215322494507\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03359253332018852\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0587288960814476\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08205880969762802\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1985856592655182\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04863128811120987\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05524565279483795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14104466140270233\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12450912594795227\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07419614493846893\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10151275247335434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17857903242111206\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03462548181414604\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032743677496910095\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02527974173426628\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06669820845127106\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08795926719903946\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03944268822669983\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05448111891746521\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10510896146297455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1230103150010109\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10805089771747589\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06297619640827179\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05053148418664932\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0581347793340683\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1527089774608612\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08396176993846893\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10839943587779999\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018339034169912338\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13162051141262054\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07666020840406418\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06594698876142502\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05252760276198387\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08206266164779663\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06590606272220612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059487923979759216\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.0909058228135109\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09148485213518143\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021809909492731094\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047466032207012177\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048377182334661484\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10399451851844788\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09391172975301743\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0740467756986618\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04466485232114792\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06089002266526222\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0467509888112545\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05132460594177246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020760005339980125\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04764310270547867\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027682587504386902\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023883866146206856\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21097272634506226\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18519166111946106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0600900873541832\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08561835438013077\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09220628440380096\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15766751766204834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1039520725607872\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05141056329011917\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0516340509057045\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10025250166654587\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0673893541097641\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.054407864809036255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03521202504634857\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04324881359934807\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0358675979077816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06375227868556976\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024976730346679688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04917693883180618\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030831973999738693\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03765473514795303\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05676313489675522\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1199585348367691\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.160708487033844\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02661541849374771\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06780526787042618\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0921141728758812\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030197391286492348\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05763237178325653\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055622100830078125\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03224283456802368\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13053429126739502\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06326048076152802\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02047562599182129\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02838342823088169\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.143338143825531\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.075882688164711\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07237816601991653\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.289490282535553\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08947357535362244\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0430474728345871\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08826704323291779\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08736879378557205\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0989006906747818\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.36871832609176636\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11028783023357391\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0449717678129673\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07422588765621185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09257455170154572\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.2318500131368637\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0502818301320076\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09630010277032852\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06709171831607819\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.23766416311264038\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17667347192764282\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025987902656197548\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08417993038892746\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18063458800315857\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14708688855171204\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03741078078746796\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07615058124065399\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026495084166526794\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05768139660358429\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033861711621284485\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07200799882411957\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06903587281703949\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08000483363866806\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031139617785811424\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10947445780038834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05201264098286629\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045075658708810806\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09163745492696762\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032636500895023346\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06958495825529099\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016152266412973404\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10010756552219391\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0299089215695858\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08688760548830032\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04002600163221359\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11186511814594269\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23613664507865906\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05021625757217407\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1363934576511383\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10496021062135696\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07359687983989716\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07385878264904022\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014326849021017551\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08968683332204819\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25322842597961426\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08378980308771133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07816906273365021\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15014231204986572\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1097739189863205\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027510076761245728\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11076328158378601\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10714545845985413\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06467395275831223\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04436580464243889\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07450016587972641\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05915586277842522\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014584403485059738\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.051411472260951996\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03132294863462448\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06731986999511719\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0523679256439209\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11543066799640656\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.27388450503349304\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01613885536789894\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0441165491938591\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13118581473827362\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1948612928390503\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04311603680253029\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07537229359149933\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09169411659240723\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026972316205501556\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02549256943166256\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12693998217582703\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09164091944694519\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05204702541232109\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08440318703651428\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07690256834030151\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.35551655292510986\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16216367483139038\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010623231530189514\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07068992406129837\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19211217761039734\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06474479287862778\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11945442110300064\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056624531745910645\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12029418349266052\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1634727120399475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040244221687316895\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18339893221855164\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07685858011245728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03953813016414642\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12655532360076904\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05414741486310959\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059177979826927185\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16564561426639557\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16010528802871704\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12061785161495209\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13031046092510223\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14704352617263794\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0313287228345871\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0446150042116642\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06919510662555695\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04833388701081276\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13923709094524384\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1381949633359909\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13466447591781616\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06418123096227646\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.201534703373909\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029126722365617752\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0550650916993618\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1417858600616455\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023703008890151978\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0384131520986557\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09666234254837036\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17054881155490875\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10096335411071777\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011379214003682137\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08395369350910187\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18369664251804352\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09937882423400879\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17938408255577087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05307023227214813\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03660035878419876\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12439372390508652\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15712742507457733\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1548071801662445\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09053067862987518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0364329032599926\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0326949842274189\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11438706517219543\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0912368893623352\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03648703545331955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03589632362127304\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08765412867069244\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.22395402193069458\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16600191593170166\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06255097687244415\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23196770250797272\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08716113865375519\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01298183761537075\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06202227249741554\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1854366660118103\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05558083578944206\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07420573383569717\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11480860412120819\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10526207089424133\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12660673260688782\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11998462677001953\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1928553283214569\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07905937731266022\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08274855464696884\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026434332132339478\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08518831431865692\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18687297403812408\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02626422792673111\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08102991431951523\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0273795984685421\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06036226451396942\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11848554015159607\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04138822853565216\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09935136884450912\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04213697463274002\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06769464910030365\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08498741686344147\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04155935347080231\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1584022045135498\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062182024121284485\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06600134819746017\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02979336306452751\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09369450807571411\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038799770176410675\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027217017486691475\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14272844791412354\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12398265302181244\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030630767345428467\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06686989963054657\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052295982837677\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043450236320495605\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04857899993658066\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.32414865493774414\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15379215776920319\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0692712813615799\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02085448056459427\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06524413824081421\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013768499717116356\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06449007987976074\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06419934332370758\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07734058052301407\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11488238722085953\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05136319622397423\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02459079772233963\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09823433309793472\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02672102488577366\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06859593838453293\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.042148105800151825\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06328225880861282\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025457657873630524\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0728173553943634\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11376695334911346\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04839625954627991\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06652191281318665\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024777255952358246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029497550800442696\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056173138320446014\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03137734532356262\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021968014538288116\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.21978482604026794\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0507861003279686\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10846111178398132\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08203292638063431\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06618598848581314\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056821130216121674\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04617233946919441\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026377614587545395\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18492381274700165\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10744458436965942\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03736141696572304\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05688854306936264\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.055253252387046814\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09606730937957764\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09408090263605118\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07637493312358856\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11472022533416748\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17643728852272034\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11411863565444946\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016792410984635353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025183014571666718\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1459597647190094\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13880464434623718\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09556964039802551\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13243550062179565\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01763741672039032\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021723438054323196\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0828954353928566\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05117044225335121\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2172282487154007\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06461349874734879\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014059629291296005\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08817288279533386\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15390217304229736\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026861727237701416\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1896296739578247\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03128615766763687\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13063885271549225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06304831057786942\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012599575333297253\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028257407248020172\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03519279137253761\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031102515757083893\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14722222089767456\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01930069364607334\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031638775020837784\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0226724985986948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04749486222863197\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16600272059440613\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09220104664564133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03281449154019356\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13673752546310425\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09315045922994614\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.16968846321105957\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05600845068693161\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011094669811427593\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11184246838092804\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1744365692138672\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08428410440683365\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16042599081993103\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09861791133880615\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1892675757408142\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06893359869718552\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06178732588887215\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037974171340465546\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04143481329083443\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1604597419500351\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10104846954345703\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11270591616630554\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08561882376670837\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02664250135421753\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05460253730416298\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03935009241104126\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059456147253513336\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06492562592029572\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03449009731411934\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14135420322418213\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09401160478591919\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19977250695228577\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0640866756439209\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07504288852214813\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09359169006347656\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06897780299186707\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06372922658920288\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14308755099773407\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11489685624837875\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13397319614887238\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06488877534866333\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07300775498151779\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1261352151632309\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0791468471288681\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03175581991672516\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019214410334825516\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036114443093538284\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028737109154462814\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06887906789779663\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03942462429404259\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17667287588119507\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06802207231521606\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053676530718803406\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0828082263469696\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14264526963233948\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06767618656158447\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04210013896226883\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03177592158317566\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04039779305458069\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09225974977016449\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11087502539157867\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05266129970550537\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1031172126531601\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09414689242839813\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023322245106101036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15853813290596008\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04700774699449539\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061473652720451355\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10719539225101471\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048657774925231934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08478173613548279\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05437253415584564\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14623551070690155\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08936036378145218\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051843222230672836\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029616570100188255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023625336587429047\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05886270850896835\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.1548803746700287\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13332504034042358\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016841568052768707\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03408639505505562\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13804176449775696\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0686798244714737\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10377243906259537\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07091197371482849\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19235959649085999\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10443273186683655\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014895894564688206\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18717634677886963\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06901378184556961\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13663506507873535\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03423082083463669\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026927024126052856\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045322660356760025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060688428580760956\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07448463141918182\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10323111712932587\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13318757712841034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04386544227600098\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05008954182267189\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06666646152734756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014689859934151173\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12097945809364319\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04892367869615555\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1775985062122345\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16843070089817047\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04582109674811363\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046781472861766815\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030139505863189697\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08109104633331299\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13079839944839478\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11997772008180618\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0614505410194397\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2928260564804077\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060688793659210205\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04035767540335655\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03898146003484726\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05970095098018646\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14354462921619415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04363146051764488\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06959661841392517\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05474965646862984\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014896849170327187\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03834375739097595\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023898448795080185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05186887085437775\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08937164396047592\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15155689418315887\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16156291961669922\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030966373160481453\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06533941626548767\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0568101704120636\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1372058093547821\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11844661086797714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05433225259184837\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16636481881141663\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18818268179893494\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1003464013338089\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06358403712511063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0516732819378376\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022428423166275024\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0578080490231514\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034035515040159225\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05742153525352478\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19270899891853333\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07448829710483551\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03545999526977539\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08228933811187744\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09657841920852661\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034533288329839706\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10212361812591553\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.023003172129392624\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03885343670845032\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08583136647939682\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07195962965488434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08115603029727936\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10418765246868134\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08458340913057327\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07764309644699097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055154234170913696\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11368047446012497\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018085023388266563\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016023438423871994\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1272992342710495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058522313833236694\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07230687141418457\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07098757475614548\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07779262959957123\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03698548302054405\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15451973676681519\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07088163495063782\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05393432825803757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05646961182355881\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06574086844921112\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10688909888267517\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046674806624650955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0614410936832428\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1310247927904129\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029261520132422447\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04448612779378891\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08474843949079514\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1462765336036682\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15897968411445618\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1065758615732193\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06907951086759567\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13412031531333923\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10181164741516113\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040491241961717606\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08177858591079712\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12542293965816498\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05255232751369476\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09486046433448792\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1808139681816101\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03171253576874733\n",
      "\n",
      "\n",
      "Validation accuracy: 96.9\n",
      "\n",
      "\n",
      "Epoch 7..\n",
      "Training accuracy: 100.0\tTraining loss: 0.02362937480211258\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09293889999389648\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07619106769561768\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1256169080734253\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15093182027339935\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025773048400878906\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12300242483615875\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02791324444115162\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03178120404481888\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13232629001140594\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09486623108386993\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06346659362316132\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04109366610646248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011957159265875816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03314785286784172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06149009242653847\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0290155578404665\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037908636033535004\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04149612784385681\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031276918947696686\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04794108495116234\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07415881752967834\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08474525064229965\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09061593562364578\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11447887122631073\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05823398008942604\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03574216365814209\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018608754500746727\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.042078807950019836\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08784730732440948\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11486758291721344\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05453745275735855\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014212552458047867\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03988677263259888\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03155018389225006\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04761647433042526\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09980074316263199\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07584234327077866\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057485755532979965\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0694446861743927\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07370622456073761\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07992743700742722\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038212426006793976\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05708473175764084\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022279702126979828\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07275065779685974\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06249557062983513\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21316444873809814\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1199558675289154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09699146449565887\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05607616901397705\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017208818346261978\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14890247583389282\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1727597713470459\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042485252022743225\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15551039576530457\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10201770812273026\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10335790365934372\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09100016206502914\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055261388421058655\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044568561017513275\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1152707189321518\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08394898474216461\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09262587875127792\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042918525636196136\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0496428944170475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07401017844676971\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0730457603931427\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11234937608242035\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040607646107673645\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024008743464946747\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14676916599273682\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1040554940700531\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07568970322608948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043567441403865814\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03678032383322716\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06883955001831055\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05719635635614395\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06932426989078522\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1480410248041153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03432237729430199\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12092624604701996\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08307703584432602\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05610217899084091\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03468197211623192\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04517956078052521\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05197307467460632\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13562458753585815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057714514434337616\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10919544100761414\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08911892771720886\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07203282415866852\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02720724791288376\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056057997047901154\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04807324707508087\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13388140499591827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0767093151807785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0822983831167221\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11358307301998138\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06549961119890213\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035584256052970886\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035386066883802414\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04268275201320648\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04761844500899315\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022985132411122322\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08120593428611755\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1447131633758545\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048798687756061554\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022656511515378952\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04757247120141983\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04340018332004547\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04497663676738739\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045445263385772705\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04718302562832832\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02699742466211319\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05104456841945648\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013048121705651283\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2593993544578552\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019142933189868927\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024439740926027298\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06059446185827255\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.087163046002388\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017366893589496613\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08124096691608429\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14455968141555786\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028865989297628403\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06318451464176178\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12093251943588257\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033950209617614746\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18875199556350708\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08014063537120819\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10776297003030777\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04269512742757797\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04875236377120018\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06552663445472717\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12581601738929749\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034518007189035416\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09081466495990753\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0713399276137352\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09928573668003082\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07714641094207764\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05836738646030426\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0356653667986393\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12216226756572723\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025545591488480568\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.047394439578056335\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10885082185268402\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028054099529981613\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04569075256586075\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12446845322847366\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08924736827611923\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04896274581551552\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02223711833357811\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02446066215634346\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14477986097335815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13230860233306885\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042770326137542725\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018583869561553\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04266084358096123\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04517250508069992\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21452823281288147\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08601003885269165\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15285030007362366\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24784240126609802\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15201136469841003\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021480800583958626\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05962063744664192\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05008728802204132\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.050008729100227356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04740465059876442\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16436585783958435\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08519554883241653\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12389817833900452\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06512685120105743\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19735871255397797\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06508097052574158\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10693325847387314\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10174799710512161\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04218132793903351\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1434917449951172\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050598740577697754\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06267443299293518\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.12314879894256592\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03394490107893944\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0521550215780735\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08474200963973999\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05246313661336899\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06892623752355576\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05633958429098129\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03439702093601227\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09163602441549301\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05432930961251259\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04848760738968849\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04035823792219162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06602764129638672\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033359870314598083\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08190691471099854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06732024252414703\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0512327179312706\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08290962129831314\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1048327088356018\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08054959028959274\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17244189977645874\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02876758947968483\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059392478317022324\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03548330068588257\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06032424047589302\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018349822610616684\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006645059213042259\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038762032985687256\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038478367030620575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.063577800989151\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026062985882163048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05312369763851166\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06570243835449219\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039001740515232086\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025600694119930267\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0660889744758606\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08012337982654572\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.053749263286590576\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038848262280225754\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07201413810253143\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020470231771469116\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08035408705472946\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.046035826206207275\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031889498233795166\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04098306968808174\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027389317750930786\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06551490724086761\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05272018164396286\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030456455424427986\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06323707103729248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026818323880434036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07369405031204224\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10056118667125702\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04482094570994377\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.056131474673748016\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007964890450239182\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04385087639093399\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05830945819616318\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06055603548884392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07436421513557434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06848928332328796\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03458203375339508\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06666910648345947\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037588316947221756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028376488015055656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05803364887833595\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.254225492477417\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04629034176468849\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013339357450604439\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07758893817663193\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06318888813257217\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1374937891960144\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0656980350613594\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07954870164394379\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08160211890935898\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04555616155266762\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07792368531227112\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08383375406265259\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07050251960754395\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02275216020643711\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05187351256608963\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05078132823109627\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05242457240819931\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010052172467112541\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1117512509226799\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04729365557432175\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0584799200296402\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12251029163599014\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07048575580120087\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07490330934524536\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06376227736473083\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08737048506736755\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01756325364112854\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012154748663306236\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12289978563785553\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02783668413758278\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07083479315042496\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1300291121006012\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1676706224679947\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.168104350566864\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.224838525056839\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06918196380138397\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06407371163368225\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21130099892616272\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013853390701115131\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03406498208642006\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11661802977323532\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03864642232656479\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07277166098356247\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02156040444970131\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0440429151058197\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05172519013285637\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016117414459586143\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.059603359550237656\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17236745357513428\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06938367336988449\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1550247222185135\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03179677575826645\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06679653376340866\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08005554229021072\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015736078843474388\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07498065382242203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11169914901256561\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06616176664829254\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06900496780872345\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04150695726275444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05577991157770157\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032038457691669464\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043040111660957336\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05198562145233154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07183090597391129\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01516224816441536\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0324883796274662\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07418546080589294\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14829789102077484\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07079505920410156\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04119105637073517\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07911613583564758\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0689583271741867\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12282072007656097\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025738924741744995\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027513781562447548\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021664706990122795\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10543179512023926\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03340709209442139\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0954495519399643\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15996980667114258\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026289695873856544\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06818590313196182\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062283195555210114\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02901659533381462\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14392629265785217\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1632816046476364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08195021748542786\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022111766040325165\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014929702505469322\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07991296797990799\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10159093886613846\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07377937436103821\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05278715491294861\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014122690074145794\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0787644237279892\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020332155749201775\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029243148863315582\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05978361517190933\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029369138181209564\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15954428911209106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07277733087539673\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016393043100833893\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032433561980724335\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08781291544437408\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04697176814079285\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09932743012905121\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023104816675186157\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043556660413742065\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03613772243261337\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06041792035102844\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07510814070701599\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011581767350435257\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051374852657318115\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1584622859954834\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2229345291852951\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11630701273679733\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11325398087501526\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029223401099443436\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042219989001750946\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06501838564872742\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020804671570658684\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07675759494304657\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02518063224852085\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05816149711608887\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06263121217489243\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021406354382634163\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03266911208629608\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1012115553021431\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09090195596218109\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10003894567489624\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07572199404239655\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10729163885116577\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0637674480676651\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09036025404930115\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1109314039349556\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10394831001758575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08798152953386307\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02434576489031315\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08387783169746399\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027639709413051605\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1575210839509964\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05788006633520126\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013408111408352852\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03720451518893242\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04680394381284714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08203870058059692\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020911652594804764\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03183475136756897\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04263567924499512\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05279862880706787\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13322186470031738\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.060664206743240356\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06196172535419464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0867723673582077\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015431247651576996\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1503552347421646\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04860088974237442\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11154802143573761\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054199546575546265\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038513556122779846\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025300562381744385\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10810241103172302\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17925375699996948\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2494761049747467\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05390772596001625\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10008566826581955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03366096690297127\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06857258081436157\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05963943898677826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019475875422358513\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055820293724536896\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03918962553143501\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12021489441394806\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12920519709587097\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07109953463077545\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02833562158048153\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022688768804073334\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03797805309295654\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13334757089614868\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04146045446395874\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05604720488190651\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12247201800346375\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07911916077136993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05084487795829773\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07950150966644287\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0534062460064888\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08750742673873901\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08205059170722961\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04149258881807327\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08443136513233185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10569664090871811\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030482210218906403\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10700714588165283\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03943415731191635\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20957398414611816\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.051582083106040955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0416187047958374\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018604915589094162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05141685903072357\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1020449548959732\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12028345465660095\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.049921996891498566\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08215872943401337\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08023654669523239\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07703714817762375\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12212156504392624\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06720947474241257\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04367063194513321\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0661405622959137\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08644477277994156\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07423414289951324\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05016815662384033\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08941754698753357\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07861416786909103\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07582324743270874\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07003352791070938\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10993227362632751\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07229401171207428\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10986924171447754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040646377950906754\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.056940093636512756\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1803172528743744\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08434802293777466\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021354995667934418\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029699508100748062\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15326392650604248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026726331561803818\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0605335496366024\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0722888857126236\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01916283369064331\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06153488904237747\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10345742106437683\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07105566561222076\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08909446746110916\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04077092185616493\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07338771224021912\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18216359615325928\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14191876351833344\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03271881863474846\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03987247496843338\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03550761565566063\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020482640713453293\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020549094304442406\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2535327076911926\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0895877406001091\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011380000039935112\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11492253094911575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038587503135204315\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03464889898896217\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029763709753751755\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03688720241189003\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06294183433055878\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23373925685882568\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11263461410999298\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03910046070814133\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11401505023241043\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11707344651222229\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08017401397228241\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016000991687178612\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060976773500442505\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11821684241294861\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11631285399198532\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09229409694671631\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.050068166106939316\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07091715186834335\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06630900502204895\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11117323487997055\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035280805081129074\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13667017221450806\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1365247517824173\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12750126421451569\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040422696620225906\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029882041737437248\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11078082770109177\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04014518857002258\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08680862188339233\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010306219570338726\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04925242438912392\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.057801928371191025\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13189761340618134\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016806751489639282\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.24727044999599457\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07899600267410278\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10558490455150604\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045490991324186325\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03918393328785896\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02411072701215744\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043822288513183594\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01732395775616169\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08266813308000565\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036504458636045456\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14735147356987\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029003527015447617\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06198617443442345\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06314899027347565\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05940871313214302\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18243896961212158\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0488140843808651\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05658143758773804\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10997970402240753\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1858479529619217\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044351283460855484\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10776752233505249\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.24642698466777802\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015846818685531616\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009597202762961388\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023009322583675385\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18409298360347748\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055265773087739944\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11466795951128006\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023417674005031586\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08440246433019638\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05192285031080246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0340581014752388\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022795669734477997\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031908757984638214\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08522119373083115\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13289594650268555\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08704006671905518\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18643078207969666\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.15485794842243195\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02582588978111744\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06323014199733734\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028313230723142624\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0988774523139\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03295162320137024\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.041956763714551926\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10509968549013138\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0779053270816803\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13422541320323944\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19157926738262177\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014127743430435658\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0526408776640892\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09311413764953613\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04601692035794258\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02703925222158432\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028670385479927063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026921233162283897\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.25983813405036926\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06841076910495758\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.023207983002066612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043452806770801544\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0641317367553711\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028029510751366615\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03077436424791813\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09466776996850967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.022616995498538017\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037777431309223175\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06962418556213379\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02806813083589077\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11894020438194275\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07094773650169373\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012995962984859943\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053986355662345886\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08098840713500977\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08123965561389923\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043245479464530945\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24762022495269775\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04979103431105614\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06313970685005188\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16039007902145386\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1028984859585762\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04117216914892197\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05089077726006508\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17873147130012512\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11204780638217926\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15482918918132782\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05078675597906113\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11320411413908005\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04539203643798828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06748294085264206\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11571736633777618\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027461698278784752\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02808753214776516\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04440298303961754\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033790700137615204\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05160203576087952\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046547308564186096\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1469050496816635\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047936804592609406\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048984259366989136\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021935276687145233\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07141082733869553\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019307738170027733\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09589570015668869\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09977029263973236\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01264853123575449\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04210086166858673\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.25178244709968567\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08918265998363495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06597192585468292\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03814823180437088\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.058295562863349915\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0906124860048294\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0501323863863945\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03020060993731022\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06404738128185272\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1954146921634674\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15686354041099548\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06804507225751877\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03822243958711624\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05635574460029602\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2109241783618927\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018637005239725113\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0659189447760582\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1319991648197174\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033052828162908554\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030447805300354958\n",
      "\n",
      "\n",
      "Training accuracy: 90.62\tTraining loss: 0.15874475240707397\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08387459069490433\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1644403040409088\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059971898794174194\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2971062660217285\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07169415056705475\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0871921181678772\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01498758140951395\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11109068989753723\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03181299939751625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029218725860118866\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09518209099769592\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03845188766717911\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13434959948062897\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14000451564788818\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10093098133802414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02451849728822708\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08266668021678925\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00864310935139656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1288244128227234\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1809440404176712\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08022429794073105\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09932798892259598\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07521191239356995\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05045774206519127\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0589250773191452\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.108955018222332\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09119679033756256\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0762862041592598\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04380074888467789\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05125463008880615\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032597754150629044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10934708267450333\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025462977588176727\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11698576807975769\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029905643314123154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09689399600028992\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08239339292049408\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08767466247081757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057692356407642365\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07147643715143204\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05014308542013168\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04494389891624451\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016391105949878693\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1167091429233551\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009935054928064346\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03003065288066864\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0375729463994503\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11556152999401093\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07653085142374039\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08691149950027466\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030285868793725967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0560971163213253\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03198561444878578\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05689575523138046\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08212703466415405\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0908588320016861\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021172909066081047\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18571268022060394\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.23188738524913788\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017916973680257797\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17040109634399414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012543256394565105\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06576462090015411\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04735427349805832\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17594300210475922\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05377329885959625\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.058108776807785034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07648354768753052\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07896781712770462\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09308962523937225\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03874557837843895\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03878859058022499\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019520228728652\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19640198349952698\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0824306309223175\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.2668497562408447\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.052043814212083817\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18440669775009155\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08265328407287598\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0710163488984108\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04244101047515869\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059390872716903687\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07984054088592529\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04164530336856842\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.059495098888874054\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019015250727534294\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08248201757669449\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03446773812174797\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03267867490649223\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043454136699438095\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033116310834884644\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03517482429742813\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027637241408228874\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053654514253139496\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14466150104999542\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.056790463626384735\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09451106190681458\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05620802193880081\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047057971358299255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014865915291011333\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07013639807701111\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04027996212244034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08910515904426575\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015611117705702782\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01375003345310688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0569271519780159\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035596948117017746\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05301374942064285\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058044515550136566\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17355459928512573\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03315865993499756\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02803146094083786\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04222442954778671\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11559388041496277\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08142028748989105\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1386740803718567\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024841293692588806\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08843474090099335\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01304288487881422\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045300357043743134\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03442465886473656\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013975869864225388\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06757350265979767\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016323354095220566\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05684400349855423\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05845363438129425\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14102333784103394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018137741833925247\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.05450526624917984\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05292672663927078\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05256737396121025\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017334159463644028\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03806579113006592\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14240825176239014\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021061697974801064\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06255905330181122\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0720648393034935\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03138180822134018\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07815369218587875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04983516037464142\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037183213979005814\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10695959627628326\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10615568608045578\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17640012502670288\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10744468122720718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06480354070663452\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07866737246513367\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02988932654261589\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13521702587604523\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18269214034080505\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016398221254348755\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03239589184522629\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0364161916077137\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08226571977138519\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14978426694869995\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014056889340281487\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041868384927511215\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15500205755233765\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06732335686683655\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04042336344718933\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013871015049517155\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05578494444489479\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054240256547927856\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024920079857110977\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10077755898237228\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14273761212825775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11494826525449753\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06500333547592163\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07063985615968704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07704958319664001\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04336712881922722\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04476689547300339\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08561194688081741\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011171428486704826\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06656695902347565\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0990927517414093\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07230842858552933\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06311702728271484\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08825810253620148\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06570980697870255\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12797142565250397\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025755921378731728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03013862669467926\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08905284106731415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08641040325164795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048236358910799026\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051796749234199524\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05830393731594086\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02118491195142269\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1697888821363449\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01624174229800701\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08488002419471741\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21315427124500275\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19520127773284912\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1686515510082245\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03037658892571926\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06655014306306839\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10718467831611633\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05404701828956604\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012096659280359745\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04991313815116882\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07390474528074265\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1622847318649292\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02541070245206356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006423247046768665\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06789808720350266\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01477753184735775\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13201382756233215\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02107059955596924\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12520292401313782\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07334674894809723\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11063458770513535\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04157901927828789\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046029768884181976\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04497099667787552\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007643279619514942\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054081179201602936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038793522864580154\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03460056334733963\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04410947486758232\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11067815870046616\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06635254621505737\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0595291405916214\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03668692708015442\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024609463289380074\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06641989201307297\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09788616746664047\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047021035104990005\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12569975852966309\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08872342109680176\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1275002658367157\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08722174167633057\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08130306005477905\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11562369018793106\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09596481174230576\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15083548426628113\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07457195222377777\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07381851226091385\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029810210689902306\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03607581555843353\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07530904561281204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1520807147026062\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08881077170372009\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029413748532533646\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03122204914689064\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04063636437058449\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016458824276924133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06866275519132614\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023794159293174744\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13272759318351746\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0594053715467453\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04647992551326752\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01510096900165081\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040381524711847305\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10421275347471237\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0352385975420475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04482866823673248\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09199671447277069\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019475048407912254\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028741350397467613\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02539987489581108\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.08566345274448395\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03285441920161247\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08904874324798584\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02677147462964058\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06273658573627472\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07621457427740097\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1791297197341919\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028578028082847595\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051107969135046005\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09520839154720306\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012356042861938477\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08962785452604294\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042777854949235916\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09272848814725876\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032894667237997055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0398893803358078\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042372237890958786\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035647496581077576\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1291472613811493\n",
      "\n",
      "\n",
      "Validation accuracy: 96.94\n",
      "\n",
      "\n",
      "Epoch 8..\n",
      "Training accuracy: 100.0\tTraining loss: 0.0436871275305748\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10183659195899963\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11691123247146606\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019723735749721527\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08594342321157455\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024319330230355263\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.172215074300766\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07979782670736313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035533297806978226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10953104496002197\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031052708625793457\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03919848054647446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04734586924314499\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03468978404998779\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18333907425403595\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14955152571201324\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026000594720244408\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0758984386920929\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03482956439256668\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16061292588710785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09054861962795258\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13183599710464478\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15737810730934143\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0493423193693161\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03938142955303192\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05136163532733917\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028790343552827835\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05853036791086197\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026937754824757576\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0463060662150383\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06890669465065002\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13622888922691345\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.07701551914215088\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05124252289533615\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05665048584342003\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029756903648376465\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08777482807636261\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05468745157122612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11580020189285278\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05760258808732033\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016722064465284348\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050142742693424225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08230607956647873\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032479070127010345\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14316251873970032\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08599027991294861\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008801239542663097\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00833519920706749\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0463825948536396\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021889884024858475\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06328701227903366\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03087422251701355\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01563001051545143\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04593592882156372\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05746026337146759\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056212417781353\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07229573279619217\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02425932139158249\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06906788051128387\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04184703156352043\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06251652538776398\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09237125515937805\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1542300432920456\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048353709280490875\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03400712460279465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05559496954083443\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04281380772590637\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04679290950298309\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09834479540586472\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08818969875574112\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04730019345879555\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018061736598610878\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033981986343860626\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03988298773765564\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033983245491981506\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.041788868606090546\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08339064568281174\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0193901676684618\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026282547041773796\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12710952758789062\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013157928362488747\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02098863199353218\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09307347983121872\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026432644575834274\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03843780606985092\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008376816287636757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034777235239744186\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09521805495023727\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12194255739450455\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017765719443559647\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06654465198516846\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025071056559681892\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05014543980360031\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04265861213207245\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03451605513691902\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10523297637701035\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045068733394145966\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028027283027768135\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015046634711325169\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029462166130542755\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03242606297135353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025673137977719307\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025754692032933235\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07557086646556854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056301821023225784\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03214342147111893\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04228968545794487\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07684805989265442\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011866336688399315\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05658528953790665\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06807764619588852\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03009161166846752\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02665463089942932\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12795217335224152\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019698720425367355\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05632924288511276\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07724557816982269\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.047116681933403015\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03770144283771515\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10150342434644699\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026989886537194252\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04159067943692207\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055446427315473557\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01899060793220997\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017790060490369797\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019438978284597397\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025859344750642776\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.023688090965151787\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08223504573106766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08420577645301819\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06838809698820114\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.108483225107193\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.176946222782135\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012267075479030609\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029443304985761642\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05721619725227356\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04145268350839615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06372964382171631\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043877795338630676\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029800912365317345\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05141109600663185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06302323192358017\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10476738214492798\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09618672728538513\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0070229205302894115\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03139812499284744\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.24626319110393524\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10526791960000992\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031211497262120247\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0227496437728405\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11936827003955841\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04085295647382736\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049915213137865067\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05321027711033821\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05591107904911041\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0902034342288971\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.05658702924847603\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13092513382434845\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0900893360376358\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013678353279829025\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019882118329405785\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07489670068025589\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009789252653717995\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07585243880748749\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030942846089601517\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006861406844109297\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053620994091033936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04395702853798866\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.046588219702243805\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09043103456497192\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00960003212094307\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027521170675754547\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11546279489994049\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06903596222400665\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014604036696255207\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13234689831733704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1015823557972908\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017546212300658226\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12539511919021606\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21311873197555542\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0358206182718277\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03214624524116516\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08456578105688095\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11542408913373947\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10154984891414642\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.046433787792921066\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021217139437794685\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018672756850719452\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.051950909197330475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049489863216876984\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14553119242191315\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024963753297924995\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03556342422962189\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20978675782680511\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06390567123889923\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10871388018131256\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005603666417300701\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10479380190372467\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06054217368364334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07795514166355133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034150008112192154\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013113776221871376\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06605497002601624\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05620822310447693\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08440307527780533\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017908114939928055\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17641396820545197\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025977905839681625\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055730827152729034\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060505956411361694\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03151556849479675\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014860997907817364\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09826712310314178\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048444755375385284\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05081098526716232\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03951813653111458\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009402027353644371\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034698486328125\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13016721606254578\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09466450661420822\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039329204708337784\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.134006530046463\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08775689452886581\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0471850261092186\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1377112865447998\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061980027705430984\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10618755966424942\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034303680062294006\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03480779379606247\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04102976992726326\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13077226281166077\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03166469931602478\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07197920978069305\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03780142590403557\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05381164699792862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06405746936798096\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07228369265794754\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05230097100138664\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0691031962633133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055959027260541916\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021776709705591202\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02625306323170662\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02974599599838257\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029106872156262398\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036625925451517105\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04510979354381561\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02076197788119316\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04080266132950783\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0476626455783844\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07915595918893814\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.048492852598428726\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06462132930755615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04334457963705063\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02543165534734726\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06257976591587067\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033627286553382874\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03837936371564865\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07795467972755432\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027296047657728195\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07823851704597473\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05379011482000351\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15304350852966309\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05207471922039986\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08785398304462433\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024614542722702026\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10973924398422241\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05462009459733963\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044116757810115814\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04870942234992981\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09531283378601074\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047387026250362396\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021029619500041008\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035377442836761475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06704901158809662\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025434046983718872\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033562932163476944\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03849519416689873\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03733135387301445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01485673151910305\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026866968721151352\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.128871351480484\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03362378850579262\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0131344860419631\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008789092302322388\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023000918328762054\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.053122628480196\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06996103376150131\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028974737972021103\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1271551549434662\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08685022592544556\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.06211026757955551\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02722799777984619\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14230042695999146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0899340957403183\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020743107423186302\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010284174233675003\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.057906635105609894\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06821345537900925\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12209546566009521\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08647957444190979\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045476026833057404\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011238603852689266\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023518912494182587\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014579921960830688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09211955964565277\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054500821977853775\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08115490525960922\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01792592741549015\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13131342828273773\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.038627639412879944\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09102381765842438\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019989177584648132\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018428198993206024\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12317660450935364\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027092522010207176\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08476923406124115\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11994831264019012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06190158426761627\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029010774567723274\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.056004058569669724\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10381817817687988\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03924177587032318\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032331712543964386\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05567413195967674\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0685078352689743\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07741977274417877\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016058512032032013\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02539929747581482\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11595205217599869\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05805711820721626\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20334716141223907\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11134146898984909\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057858191430568695\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0711747482419014\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01057802140712738\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06965939700603485\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03469875454902649\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03818926587700844\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06858300417661667\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07833041995763779\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07616454362869263\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02999669685959816\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09726472944021225\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01789400912821293\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024955276399850845\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027416551485657692\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05799340456724167\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028710579499602318\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027839047834277153\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10201748460531235\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09544896334409714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05802987515926361\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0645635724067688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06340177357196808\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08533353358507156\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02078404650092125\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0381140261888504\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024258170276880264\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1056155413389206\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04423333704471588\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04689761996269226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06838494539260864\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05893275886774063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03874655067920685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11559651792049408\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13358737528324127\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027775388211011887\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05691724270582199\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029748965054750443\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022266168147325516\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04424343258142471\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04898323491215706\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03935347497463226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04326465353369713\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07344190031290054\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04471760243177414\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06778784096240997\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026605108752846718\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09797247499227524\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09712279587984085\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10103864967823029\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10803691297769547\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13387779891490936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05114626884460449\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05515803024172783\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13183821737766266\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008467700332403183\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08678761124610901\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024657659232616425\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06933664530515671\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012975451536476612\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03308411315083504\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0530315525829792\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057887036353349686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09372090548276901\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2883598804473877\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01455067377537489\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04499427229166031\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09806156903505325\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.041533131152391434\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009879084303975105\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057494767010211945\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019796065986156464\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08456191420555115\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0343952514231205\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00805523432791233\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022997871041297913\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.044244442135095596\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16342149674892426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014855163171887398\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050144001841545105\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03949514776468277\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03526069223880768\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01614564284682274\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1043955385684967\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17708708345890045\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09480790793895721\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05018021538853645\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.040139660239219666\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02840733528137207\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016289927065372467\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027517257258296013\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08910372853279114\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03731199726462364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04169539362192154\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05894085764884949\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05392363667488098\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12955376505851746\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026012616232037544\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007467544171959162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05733206868171692\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03830470144748688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03665180504322052\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010122985579073429\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0360245555639267\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17861396074295044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057411156594753265\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06359163671731949\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.1698465794324875\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07888007909059525\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026167895644903183\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.037715937942266464\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08238892257213593\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08604251593351364\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03272729367017746\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09670531004667282\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03641357645392418\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038046665489673615\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05955652892589569\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07789348810911179\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0966045930981636\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04322473704814911\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07655653357505798\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040820226073265076\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04987870901823044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0331960953772068\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04673879221081734\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.07917901873588562\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050365716218948364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03076944872736931\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08210045844316483\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036728791892528534\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013943711295723915\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10586433112621307\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022768260911107063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.21070438623428345\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13449180126190186\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1293269693851471\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03260110691189766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04537351056933403\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011643221601843834\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0536755695939064\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06896630674600601\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014713659882545471\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02026478759944439\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1373080015182495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04330011457204819\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.13979321718215942\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06809946149587631\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012360058724880219\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023038329556584358\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12392376363277435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03303857520222664\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.044632889330387115\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031939443200826645\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12513217329978943\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09897314012050629\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050285376608371735\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02296285890042782\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07795952260494232\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1271398663520813\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12728586792945862\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16632679104804993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05849763751029968\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027509313076734543\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09257155656814575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0507698655128479\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.048024483025074005\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07593295723199844\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.128072589635849\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02714211493730545\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04591871052980423\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05113323777914047\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029537491500377655\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.060990653932094574\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09513894468545914\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05594973266124725\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1803346574306488\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04884811490774155\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028371579945087433\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0352051705121994\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048445917665958405\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05646416172385216\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0560474693775177\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027398325502872467\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050215497612953186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06893683969974518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027617741376161575\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07916706800460815\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040277741849422455\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0912046954035759\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02757001295685768\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0709855854511261\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12293930351734161\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03809357061982155\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13083964586257935\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0511101633310318\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1045699194073677\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05938195437192917\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07865352928638458\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09326811134815216\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04194048047065735\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03201916813850403\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027713894844055176\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02910592034459114\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015600323677062988\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01842299848794937\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10581841319799423\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15888848900794983\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09109866619110107\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050253115594387054\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021129395812749863\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014093942008912563\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017671840265393257\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05052253231406212\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10066942870616913\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08962256461381912\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0942029058933258\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07407806813716888\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04776393994688988\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03914947062730789\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07760612666606903\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005982621572911739\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10695324838161469\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.052451375871896744\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14910951256752014\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07446733117103577\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02823099121451378\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018704179674386978\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019363442435860634\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03337656706571579\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05150039494037628\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017302412539720535\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12416992336511612\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07623487710952759\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06498690694570541\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022360708564519882\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02590968832373619\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016522957012057304\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11745987832546234\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18478256464004517\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1506507694721222\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09175147861242294\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05510573834180832\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07357391715049744\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07566723972558975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05699244141578674\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08457072079181671\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03593693673610687\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10802855342626572\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060638729482889175\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03158089146018028\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011908724904060364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03722965717315674\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03171449899673462\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017755838111042976\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1860705018043518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011077514849603176\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04033304378390312\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040764085948467255\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0996105968952179\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0994175374507904\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057897377759218216\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027866601943969727\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022308262065052986\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0978916585445404\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03377963975071907\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01474246010184288\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034056343138217926\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028331778943538666\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025332748889923096\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06220075115561485\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04003441706299782\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031272441148757935\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12258171290159225\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04785440117120743\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06346093863248825\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08856537938117981\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08732867985963821\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018776578828692436\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053848378360271454\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11379949003458023\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11807873845100403\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03325564041733742\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1629231572151184\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05858894810080528\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1180744618177414\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18545205891132355\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04016454145312309\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02123337611556053\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09317545592784882\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08872373402118683\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14394500851631165\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01375750731676817\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025813713669776917\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043053075671195984\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1547107845544815\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21454286575317383\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05489834398031235\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05956362932920456\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06310039013624191\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06306895613670349\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08340784907341003\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.19045983254909515\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10644887387752533\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10529923439025879\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014395227655768394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04869578406214714\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015120219439268112\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06985633075237274\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01845579594373703\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1339813768863678\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11169624328613281\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06883159279823303\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1140129417181015\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03634648770093918\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21989759802818298\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07618406414985657\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08843688666820526\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05265225097537041\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059809692203998566\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03770937770605087\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13085608184337616\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08024425804615021\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04669077321887016\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053368616849184036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06268219649791718\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030190663412213326\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06232651323080063\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16850151121616364\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024813057854771614\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03827298432588577\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07055022567510605\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03546897694468498\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08018004149198532\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03051367774605751\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07745359092950821\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06580224633216858\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18862482905387878\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023593194782733917\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05337436497211456\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0833824947476387\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030910924077033997\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05332108214497566\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04568967968225479\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015610035508871078\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09607303887605667\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05708456411957741\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08005604892969131\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09707357734441757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04129412770271301\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02043578214943409\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05999625474214554\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15407952666282654\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041791800409555435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04087171331048012\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12847977876663208\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04053249582648277\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027838682755827904\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008969571441411972\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03269866853952408\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07269985973834991\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03240598738193512\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021067339926958084\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11195558309555054\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07337067276239395\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06595700979232788\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.058085761964321136\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10728218406438828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08754172921180725\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08470387756824493\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0752553790807724\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02711290493607521\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023898590356111526\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.28900784254074097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02905331924557686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16040930151939392\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06431323289871216\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.019330855458974838\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07648175954818726\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11083732545375824\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05772939324378967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03841733559966087\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12344220280647278\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018875163048505783\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019659945741295815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1102995052933693\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008477427996695042\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.093165822327137\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013247453607618809\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03574535250663757\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05369165912270546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10364333540201187\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05859269201755524\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023889657109975815\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029223648831248283\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05424681305885315\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012799736112356186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048253629356622696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02149358205497265\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06939572095870972\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028623487800359726\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056402578949928284\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1764472872018814\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08844126015901566\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15635789930820465\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08203211426734924\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012472178786993027\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03130917251110077\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05699581652879715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052108705043792725\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06996997445821762\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02169785462319851\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08196067810058594\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04475952312350273\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055827487260103226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07292629033327103\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06585672497749329\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020164672285318375\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11716504395008087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062063347548246384\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009867793880403042\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22405560314655304\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03566224128007889\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02200237661600113\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03309297934174538\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01537125650793314\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025054557248950005\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022126834839582443\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036705560982227325\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1156650185585022\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05567597970366478\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0766194611787796\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049619436264038086\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05859428644180298\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1291295737028122\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03649182990193367\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0769413411617279\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01962663233280182\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22458931803703308\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08157352358102798\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025721371173858643\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058688685297966\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04913458228111267\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04768934100866318\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028351187705993652\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08540947735309601\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026208193972706795\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03311396390199661\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06371264159679413\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005113636143505573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1099032610654831\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05182276666164398\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051585279405117035\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025523655116558075\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0375690683722496\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02876453474164009\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07312995195388794\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05669309198856354\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08753720670938492\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07638292014598846\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11002221703529358\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10131627321243286\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021668754518032074\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020283130928874016\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11737222969532013\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10176654905080795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03478950262069702\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1407642513513565\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12849445641040802\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013486891984939575\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047070108354091644\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11330337822437286\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03961603343486786\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22038361430168152\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03000807948410511\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015089964494109154\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03342653810977936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05553160980343819\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015118811279535294\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11121585965156555\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07756812870502472\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1430622786283493\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020167242735624313\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19945350289344788\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01980353146791458\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04375647380948067\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027389751747250557\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03943900763988495\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08818721771240234\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04678704962134361\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013075601309537888\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011128437705338001\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09159483015537262\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14433270692825317\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031142394989728928\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04125119000673294\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007970131002366543\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07927675545215607\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05152888223528862\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019122660160064697\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0536714643239975\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.16421811282634735\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09239578247070312\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05865687131881714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044051725417375565\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10117033123970032\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13591687381267548\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026293721050024033\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044379010796546936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06631378829479218\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037275973707437515\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026611126959323883\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07285279035568237\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02031906135380268\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009521536529064178\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012981563806533813\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0252163615077734\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01646602898836136\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0733383297920227\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11578588932752609\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07946987450122833\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04977276176214218\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01679723523557186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.083688884973526\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0930633544921875\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07453996688127518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014228636398911476\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.08070091903209686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.056116607040166855\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04981788620352745\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03641454130411148\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0623960867524147\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.18796774744987488\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04615965485572815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08692286163568497\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028997931629419327\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.104542076587677\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08619458228349686\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03527317941188812\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03514838218688965\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02619865909218788\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03850771486759186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05359901487827301\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06280490756034851\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028483804315328598\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09681163728237152\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04525433108210564\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04255414009094238\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11934379488229752\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1001870408654213\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03541138768196106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051681339740753174\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1592457890510559\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025955285876989365\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049044329673051834\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0172123983502388\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.022032059729099274\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.019464604556560516\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051017649471759796\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05553865805268288\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04778691381216049\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1127430647611618\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03901337832212448\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10380224138498306\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039354100823402405\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08920454233884811\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011678442358970642\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046032488346099854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09722432494163513\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025443125516176224\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038095083087682724\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033795736730098724\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07058078050613403\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13659816980361938\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06986987590789795\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04106852412223816\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0465514101088047\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014087633229792118\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.2129160761833191\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014104078523814678\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06309990584850311\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025364307686686516\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0803581103682518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025336846709251404\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010414710268378258\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10748796164989471\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03735371679067612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055834706872701645\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04564189165830612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0535912923514843\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.20969972014427185\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0761711448431015\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07213567942380905\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03348327428102493\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020840764045715332\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018783606588840485\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1478312462568283\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05356719344854355\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20977899432182312\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09736745059490204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07801025360822678\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07699020206928253\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05754893273115158\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10866449773311615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05393959581851959\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0717257410287857\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02313901297748089\n",
      "\n",
      "\n",
      "Validation accuracy: 97.23\n",
      "\n",
      "\n",
      "Epoch 9..\n",
      "Training accuracy: 96.88\tTraining loss: 0.0708974227309227\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06106666848063469\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09209127724170685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032394152134656906\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04759569466114044\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026387624442577362\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025771748274564743\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09439786523580551\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07621470838785172\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015832196921110153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040783628821372986\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011949308216571808\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06335048377513885\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021420389413833618\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040477629750967026\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017358511686325073\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055066708475351334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04169298708438873\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12366576492786407\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0773865133523941\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020376700907945633\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03312695026397705\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.022018352523446083\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10671613365411758\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010657021775841713\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04367080330848694\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05170217901468277\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05664787441492081\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00529879005625844\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04039302468299866\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025732818990945816\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12438240647315979\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030088946223258972\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.062413837760686874\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041453272104263306\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012559765949845314\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013021355494856834\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022119998931884766\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015327327884733677\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01863313466310501\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028257444500923157\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11877863109111786\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03455401584506035\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038853276520967484\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015265743248164654\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02353237196803093\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01336611993610859\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04391111806035042\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.15436384081840515\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035738684237003326\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1186828464269638\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.018155314028263092\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048263851553201675\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058651361614465714\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049899622797966\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01281748153269291\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10730576515197754\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03182487189769745\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06743071973323822\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018288467079401016\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013892383314669132\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05653680860996246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011616192758083344\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07803892344236374\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03883441910147667\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08354462683200836\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07046690583229065\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05723969265818596\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027049437165260315\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1456388384103775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08156406879425049\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02612554468214512\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07305657118558884\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08050771802663803\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03511868789792061\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016019225120544434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034013863652944565\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06608593463897705\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022673901170492172\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.22741363942623138\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020607365295290947\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02878791093826294\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08665701001882553\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05982545018196106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042639635503292084\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030596904456615448\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03133233264088631\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08348986506462097\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061811648309230804\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052010633051395416\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03627992793917656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048714350908994675\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12975168228149414\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09881843626499176\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024765629321336746\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01572433114051819\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03108205273747444\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10618914663791656\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.049348507076501846\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010098760947585106\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018654141575098038\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03569139167666435\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006216301582753658\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03298329934477806\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.19511309266090393\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057397760450839996\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13808704912662506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06983362883329391\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04724470525979996\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02161167748272419\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05875851958990097\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04695393517613411\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013810953125357628\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13299699127674103\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04180239513516426\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.045133188366889954\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0993146002292633\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07337839901447296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03492973372340202\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048826079815626144\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022835753858089447\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03574013710021973\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04229990392923355\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040593452751636505\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02034805342555046\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21907739341259003\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07695335149765015\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012793349102139473\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06792326271533966\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06636720895767212\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03835233300924301\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051079198718070984\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03083682432770729\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02050289884209633\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04214697331190109\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011764650233089924\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05416626110672951\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.021478872746229172\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013080354779958725\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03389895334839821\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01108509860932827\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06779884546995163\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009584017097949982\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057651203125715256\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05885748565196991\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07265680283308029\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02740597538650036\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031020233407616615\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02903825417160988\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009110896848142147\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06588304042816162\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13814814388751984\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17670077085494995\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07405759394168854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14501884579658508\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11089809238910675\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06545700132846832\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1611965298652649\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12534496188163757\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030020128935575485\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04780261218547821\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04760956019163132\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10539918392896652\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014734072610735893\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039555713534355164\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028249746188521385\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024023255333304405\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02384885400533676\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07443001866340637\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0524197593331337\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15246731042861938\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1286926567554474\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036098431795835495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05667583644390106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048507194966077805\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11573945730924606\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.060101136565208435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05261842533946037\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08800096809864044\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022135471925139427\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02431550621986389\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011051135137677193\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024619542062282562\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06128497049212456\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01083889789879322\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02604321762919426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025117462500929832\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02462238073348999\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03782179579138756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03273298591375351\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07828361541032791\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032830070704221725\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0533907413482666\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018338076770305634\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1022656038403511\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009059358388185501\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018376056104898453\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04317125305533409\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14061319828033447\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02750806137919426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03244450315833092\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05355050414800644\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016821863129734993\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0149068059399724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0796307921409607\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03280692547559738\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06389365345239639\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0781424418091774\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02896965853869915\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03797789663076401\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054642029106616974\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08390799164772034\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10966158658266068\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056426752358675\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07775559276342392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04405411705374718\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02881903387606144\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034877482801675797\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04290127009153366\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05907619372010231\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08167312294244766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03043944016098976\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0688055008649826\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0993485376238823\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05036085471510887\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014379516243934631\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047716327011585236\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03717327117919922\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02914256416261196\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01952628418803215\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010310892947018147\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01691438816487789\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04936225712299347\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09410345554351807\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015559403225779533\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022104695439338684\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0458303838968277\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04041381552815437\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05172325298190117\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028774237260222435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037561386823654175\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.021912038326263428\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028074266389012337\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03174237534403801\n",
      "\n",
      "\n",
      "Training accuracy: 89.06\tTraining loss: 0.23512716591358185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07683679461479187\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048827894032001495\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11331918835639954\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05604929476976395\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029331330209970474\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07435347139835358\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034820761531591415\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034403711557388306\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1220816820859909\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02558036521077156\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04863518476486206\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14302746951580048\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04626375809311867\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07756014913320541\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10921433568000793\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03050176613032818\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.053993407636880875\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018085027113556862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04027371108531952\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06103191524744034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04887301102280617\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021193422377109528\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03969912603497505\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08883865177631378\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045547813177108765\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009542170912027359\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03829297423362732\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1408444195985794\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006412696558982134\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03564375266432762\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.021368490532040596\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05252256244421005\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08286860585212708\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04825282469391823\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049095965921878815\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07761634886264801\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021448731422424316\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03238663077354431\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012743392959237099\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0335080586373806\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006271422374993563\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07125015556812286\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.060447920113801956\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07743626832962036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10050495713949203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04023595154285431\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01221964880824089\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13442283868789673\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013802134431898594\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13586311042308807\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05367458611726761\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010729948058724403\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04061508551239967\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07720054686069489\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012204887345433235\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15646681189537048\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06978759914636612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0967547595500946\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08828095346689224\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09139189124107361\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008865924552083015\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020704850554466248\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08126230537891388\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10043065249919891\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021748609840869904\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02935730665922165\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018287736922502518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011480320245027542\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030009619891643524\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017556751146912575\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023279253393411636\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04703611508011818\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09762931615114212\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.059161774814128876\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015119561925530434\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014252245426177979\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10474595427513123\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05259048566222191\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021579444408416748\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034211087971925735\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014254473149776459\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0068460931070148945\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07804515212774277\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08417164534330368\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.019257720559835434\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007104340009391308\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02959790639579296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09804032742977142\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05508336424827576\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06687883287668228\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11024869233369827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07931045442819595\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08468852937221527\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0637282058596611\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0494096465408802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14925457537174225\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04088884964585304\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030208801850676537\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017890453338623047\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018215196207165718\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07309723645448685\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031078573316335678\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020720934495329857\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05516372621059418\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02254720777273178\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12312447279691696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036313511431217194\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022317877039313316\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10879873484373093\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07953284680843353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01571143977344036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1262403279542923\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03816881775856018\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03694573789834976\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012071955017745495\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006005812436342239\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050805673003196716\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012117957696318626\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10667773336172104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07991646230220795\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03408202528953552\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05919814109802246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015116606839001179\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04536404460668564\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0685604140162468\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01832359842956066\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016011375933885574\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09007466584444046\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021462032571434975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04743167757987976\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039347682148218155\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032408226281404495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038909316062927246\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.10430125892162323\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05473463982343674\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14409101009368896\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019311847165226936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03877675533294678\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05669450759887695\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07471846044063568\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023083170875906944\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09135898947715759\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09710590541362762\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032384298741817474\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04045060649514198\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007561138831079006\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.110311359167099\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005883840844035149\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07356834411621094\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03813375532627106\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03803877532482147\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026709608733654022\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005531672388315201\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04167380928993225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11759428679943085\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06694596260786057\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03386620804667473\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010572216473519802\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05795659124851227\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04976683109998703\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0716492161154747\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023607943207025528\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03195534273982048\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05509098619222641\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11432796716690063\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028550300747156143\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037373412400484085\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08525332808494568\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02413797378540039\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01269303448498249\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020716246217489243\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0216864962130785\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05528757721185684\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0352398157119751\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.036732014268636703\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03867105394601822\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02306801825761795\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.09478820115327835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052122704684734344\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10351765155792236\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01989779807627201\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11054907739162445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018221989274024963\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016223948448896408\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01895769126713276\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059854451566934586\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03966023772954941\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04527240991592407\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061069704592227936\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1068110466003418\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08697736263275146\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04355892539024353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009627165272831917\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0062101855874061584\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01546446606516838\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12313517928123474\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08905986696481705\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13541927933692932\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06430202722549438\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0683116763830185\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10787352919578552\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10414013266563416\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09582887589931488\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024802520871162415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06899800896644592\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07426446676254272\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023172728717327118\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05561918020248413\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07199142128229141\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12466888874769211\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05334237217903137\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04440966248512268\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011462695896625519\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061868250370025635\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0493445098400116\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025504451245069504\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07028854638338089\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04411353915929794\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00743092130869627\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05899875983595848\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010572993196547031\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020375533029437065\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018825843930244446\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.046570420265197754\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024741623550653458\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018321223556995392\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017892086878418922\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03834998980164528\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14432081580162048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009291748516261578\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01699015125632286\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011152364313602448\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03269624710083008\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027369385585188866\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055947721004486084\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023099711164832115\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03723929822444916\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010954799130558968\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020560428500175476\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06631766259670258\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15627114474773407\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02510882541537285\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15201783180236816\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07813392579555511\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07522143423557281\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.023788850754499435\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03516075015068054\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04172959551215172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06377023458480835\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10920127481222153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10057063400745392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.01936701126396656\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12311796844005585\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.048883967101573944\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08215216547250748\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01064369734376669\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053243640810251236\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11703407764434814\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03195655718445778\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16229237616062164\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01601087674498558\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016000322997570038\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08475382626056671\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017520859837532043\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016289830207824707\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07542087137699127\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08116035908460617\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00907183438539505\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.049245771020650864\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045371800661087036\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06635819375514984\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07800783216953278\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04093586280941963\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008831774815917015\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016592470929026604\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04184854403138161\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08383601903915405\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12606391310691833\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08489920943975449\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14378038048744202\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023979563266038895\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10295847058296204\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04340139403939247\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02295580506324768\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.13175898790359497\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029207587242126465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02726716175675392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05241135507822037\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006300712935626507\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12749020755290985\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18920302391052246\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09682859480381012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03306414932012558\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.19613519310951233\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09330769628286362\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05703066661953926\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014543028548359871\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06468967348337173\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05982883274555206\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030110541731119156\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027341799810528755\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051916979253292084\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09086942672729492\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08963656425476074\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050585076212882996\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01038235705345869\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07071555405855179\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04431267827749252\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13155311346054077\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03119657374918461\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04723504185676575\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04022175073623657\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012778926640748978\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0322805680334568\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02576599456369877\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058285027742385864\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013665187172591686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08033265173435211\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029604680836200714\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04646573215723038\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024429751560091972\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09884968400001526\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040410902351140976\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03282729908823967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0310091320425272\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06169396638870239\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016880981624126434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02013995498418808\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05495775118470192\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017933741211891174\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04598552733659744\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00960889644920826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022248350083827972\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019931118935346603\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030814550817012787\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08478834480047226\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10889406502246857\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021676331758499146\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.044299155473709106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04736125469207764\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.0616132877767086\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09907941520214081\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12658445537090302\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03357963636517525\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03318772092461586\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06570082902908325\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0208975151181221\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06033625453710556\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055141791701316833\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023732561618089676\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07622271031141281\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.004890629090368748\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04565083980560303\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03887340426445007\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02933906391263008\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07450132817029953\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01047891192138195\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1425420045852661\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.034480974078178406\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.22735586762428284\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025949254631996155\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02137823961675167\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016250619664788246\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01704048365354538\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.044469043612480164\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04791691526770592\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1410694569349289\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035893019288778305\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028479134663939476\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013016103766858578\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03154154121875763\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02783949300646782\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09056365489959717\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06353709101676941\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021707309409976006\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025499999523162842\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019695919007062912\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1578904241323471\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.021595515310764313\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.061320710927248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03979066386818886\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0663355365395546\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058169182389974594\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026323571801185608\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08122357726097107\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01093396358191967\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04839817062020302\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06553719192743301\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08817872405052185\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02140447497367859\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09120884537696838\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012350470758974552\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03696709871292114\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07630617171525955\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04273676127195358\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013143669813871384\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05492805317044258\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029225138947367668\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09659501165151596\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07271730899810791\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0330938845872879\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02806277573108673\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0726793110370636\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07977789640426636\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.054248079657554626\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06157736852765083\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02342616207897663\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031586043536663055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012922437861561775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09696336090564728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027782656252384186\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04963883385062218\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042644333094358444\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016922930255532265\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0385194793343544\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02674984000623226\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05933547019958496\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009926112368702888\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02590252086520195\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13292665779590607\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06485139578580856\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02973155863583088\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05535326525568962\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03720849007368088\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.004151404835283756\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04924026504158974\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14738573133945465\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09597322344779968\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0332643985748291\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.14353670179843903\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02260272577404976\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07801573723554611\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008332572877407074\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0643192008137703\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03725200146436691\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10208874195814133\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07661276310682297\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014210007153451443\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025072768330574036\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05134687200188637\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0186503604054451\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11101949959993362\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026767145842313766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05195598304271698\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07518081367015839\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03146355599164963\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.17889854311943054\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029320377856492996\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02887130156159401\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054792553186416626\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03422202169895172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08434692770242691\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08671918511390686\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06472990661859512\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024468574672937393\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010027175769209862\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1013903021812439\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015554945915937424\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2053493708372116\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07647876441478729\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11920401453971863\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07116364687681198\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.049629613757133484\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11691898852586746\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08067960292100906\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10111565887928009\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1282901167869568\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050109170377254486\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014641557820141315\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15042927861213684\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005794866941869259\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009251805022358894\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03867490217089653\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0463511124253273\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08625275641679764\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011419974267482758\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03094012849032879\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07186755537986755\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.20137476921081543\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035238929092884064\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04582563042640686\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04740755632519722\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12751352787017822\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12549099326133728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06654735654592514\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023532753810286522\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1278717815876007\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03575993329286575\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03081410564482212\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04677851125597954\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.20592576265335083\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01848858967423439\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.044026173651218414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05186077207326889\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0351443774998188\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06004275381565094\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03123968467116356\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04737190902233124\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0297976266592741\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020254114642739296\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11663569509983063\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03151725232601166\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0879109799861908\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0052094897255301476\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04213161766529083\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04171200096607208\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053395356982946396\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04810801520943642\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045086570084095\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04785217344760895\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08748805522918701\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10109148919582367\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.094627246260643\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06240001320838928\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06217871606349945\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12349794059991837\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00953811127692461\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02704980969429016\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08704939484596252\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03285347670316696\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05821552872657776\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0719974935054779\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.22746306657791138\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06546606868505478\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08230187743902206\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07120994478464127\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035331834107637405\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1248483955860138\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019429489970207214\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011156278662383556\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040941689163446426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0072015756741166115\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019939452409744263\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07135327905416489\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.145632803440094\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03611130639910698\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.19861941039562225\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07382109016180038\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03323362022638321\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0226245429366827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07679997384548187\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12884780764579773\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043568216264247894\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07017836719751358\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07538186758756638\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06761722266674042\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027319584041833878\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059189680963754654\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027351921424269676\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030786428600549698\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.18682482838630676\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033990006893873215\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13032884895801544\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008859174326062202\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10444565862417221\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03799030929803848\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14025922119617462\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018109608441591263\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12174241244792938\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08946965634822845\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011215309612452984\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02219364047050476\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026133079081773758\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0790170282125473\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025963054969906807\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08450163900852203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012672059237957\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09993745386600494\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04466922953724861\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03080601617693901\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08852130174636841\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06673969328403473\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02619345858693123\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11846094578504562\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0264127254486084\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055628322064876556\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02707885205745697\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1034783124923706\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0366341806948185\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028464144095778465\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.037288472056388855\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04455973953008652\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018772024661302567\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.16203592717647552\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1643756479024887\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08277678489685059\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08004782348871231\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059511274099349976\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12238402664661407\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027835750952363014\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04589205980300903\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055531010031700134\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09465549886226654\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015341803431510925\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01947197876870632\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028865965083241463\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1357666552066803\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06290433555841446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057057227939367294\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06440296024084091\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08585964143276215\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022170547395944595\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02309941127896309\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026998091489076614\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038322895765304565\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0165080763399601\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006099993363022804\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02065640315413475\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026053328067064285\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035695262253284454\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023331062868237495\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02377787046134472\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06011108309030533\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03167865425348282\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06464387476444244\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06361433863639832\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017313221469521523\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039790548384189606\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028429266065359116\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04839447885751724\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02097940817475319\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15207834541797638\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05373110622167587\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039390258491039276\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010753925889730453\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.020316442474722862\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.034594688564538956\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08788017183542252\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02748548984527588\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035805054008960724\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03761406987905502\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0692262277007103\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06935321539640427\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014169557020068169\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023439442738890648\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008508657105267048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020713260397315025\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028979895636439323\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08412858098745346\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.24633429944515228\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040876396000385284\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04156854376196861\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06280721724033356\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059892088174819946\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07423101365566254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18160879611968994\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048096664249897\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06915463507175446\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.14323899149894714\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01951422542333603\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016703292727470398\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015849949792027473\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.060047928243875504\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04820773005485535\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038969337940216064\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014811806380748749\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016871359199285507\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04334148392081261\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06661266088485718\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0341893769800663\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04412463307380676\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.18852302432060242\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03752633556723595\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02675854042172432\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013582868501543999\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029295548796653748\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023204226046800613\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04459547623991966\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02899315394461155\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07184445858001709\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043118782341480255\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04248787835240364\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0283447727560997\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0493270680308342\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042728789150714874\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023108040913939476\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05613408237695694\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12239445745944977\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04809550940990448\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05069364607334137\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048360154032707214\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014837587252259254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06221573427319527\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00736541161313653\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13103607296943665\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03356437385082245\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020650746300816536\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01031867228448391\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006822220049798489\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.051450133323669434\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10258859395980835\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04177394509315491\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1232176199555397\n",
      "\n",
      "\n",
      "Validation accuracy: 97.28\n",
      "\n",
      "\n",
      "Epoch 10..\n",
      "Training accuracy: 100.0\tTraining loss: 0.01868245005607605\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02537396550178528\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02105933055281639\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04625653848052025\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05839163064956665\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01443591620773077\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18881191313266754\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0962461605668068\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02303258702158928\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.021502027288079262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03977792710065842\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021359343081712723\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09512558579444885\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08671511709690094\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03640370815992355\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.035899702459573746\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0260845385491848\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027127210050821304\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11264090240001678\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053924135863780975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0365043506026268\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08540278673171997\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032752037048339844\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0507524199783802\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11098642647266388\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018249984830617905\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045585427433252335\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014424517750740051\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050339408218860626\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06779015064239502\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08736574649810791\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03480198606848717\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018243055790662766\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04596551135182381\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043540727347135544\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028881629928946495\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0665106549859047\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02208617702126503\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02078172005712986\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008204471319913864\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04979709908366203\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017063630744814873\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008338039740920067\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06688955426216125\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021598225459456444\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015158139169216156\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030977942049503326\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04194851219654083\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04746123403310776\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02133236825466156\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049332812428474426\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03591812402009964\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11300643533468246\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04240430146455765\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01702992618083954\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01040351577103138\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03450896590948105\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04000785946846008\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02078753523528576\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018015719950199127\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03823438286781311\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09493985027074814\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03913239762187004\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09354805201292038\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039939142763614655\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009753626771271229\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03391258791089058\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055723026394844055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028818871825933456\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005401171278208494\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12948353588581085\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1961885690689087\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0660434365272522\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03489597886800766\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02441118285059929\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14254066348075867\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029491961002349854\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013008097186684608\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026126543059945107\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0726812481880188\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014390852302312851\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05730576813220978\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03327415511012077\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03195339813828468\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03544703871011734\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012527555227279663\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012858696281909943\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014226231724023819\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0851140171289444\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030708294361829758\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035627588629722595\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026733048260211945\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07927102595567703\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02928827702999115\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12684795260429382\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03890266641974449\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05096970498561859\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14351214468479156\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07168956845998764\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0339394211769104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05529634281992912\n",
      "\n",
      "\n",
      "Training accuracy: 92.19\tTraining loss: 0.18110427260398865\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04629335552453995\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03439491242170334\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025180330500006676\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03519570082426071\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017903048545122147\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015916263684630394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007919920608401299\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04117481783032417\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029982173815369606\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008192922919988632\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09759629517793655\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01142948865890503\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02459208481013775\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04919734597206116\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02886047214269638\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010154418647289276\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035121578723192215\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009495926089584827\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018262507393956184\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010269107297062874\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011631143279373646\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07475213706493378\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03394078463315964\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032519642263650894\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009963634423911572\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03053370490670204\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019277628511190414\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0329100675880909\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03753199428319931\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00980937760323286\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018364550545811653\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.031589001417160034\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11131049692630768\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02733510360121727\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012247906066477299\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04465809464454651\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014461292885243893\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02527628466486931\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06837967038154602\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07825638353824615\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007990151643753052\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02537958323955536\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06048339605331421\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04701585695147514\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0375581793487072\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03923715651035309\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10755008459091187\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04734640568494797\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011624019593000412\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013798162341117859\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012251372449100018\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019110968336462975\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0647488608956337\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030974850058555603\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024166356772184372\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07134450227022171\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028195954859256744\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017017241567373276\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059754885733127594\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03892698138952255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01160444412380457\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05074997991323471\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.21898281574249268\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0226546972990036\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022330820560455322\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033944837749004364\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0488872230052948\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1723848134279251\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.050950683653354645\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015435459092259407\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05949380248785019\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11940903216600418\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03312414884567261\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05902533978223801\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12503275275230408\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015967225655913353\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010925124399363995\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01610652729868889\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08246802538633347\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07253296673297882\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022686967626214027\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009571107104420662\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05176991969347\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03917510807514191\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06973008811473846\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006167629733681679\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0731109157204628\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02114161103963852\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02612992189824581\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016009248793125153\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020170729607343674\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0468534491956234\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017397206276655197\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04108130931854248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02560097724199295\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04645511507987976\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04510260000824928\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010436154901981354\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01489305216819048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00656472984701395\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.051103200763463974\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010691543109714985\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014304077252745628\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05746364966034889\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043960414826869965\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020612243562936783\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021053068339824677\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10482814908027649\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00809246115386486\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.038735441863536835\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024809883907437325\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.21377050876617432\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03079044446349144\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04228617623448372\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0063819605857133865\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08332962542772293\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.15143609046936035\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008950209245085716\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.022547200322151184\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043855518102645874\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09832054376602173\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06971425563097\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02235260233283043\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03820404037833214\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08941435068845749\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08778561651706696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02172604389488697\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06382479518651962\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037811312824487686\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05322645604610443\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010516064241528511\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028392033651471138\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0483565554022789\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06267061829566956\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03102033957839012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05846986919641495\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12347467243671417\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.00989875104278326\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.022340234369039536\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019069461151957512\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03335636109113693\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01760287769138813\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024591587483882904\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032705649733543396\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024096699431538582\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015820514410734177\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07344241440296173\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025100627914071083\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02270147204399109\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01828286051750183\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04013022780418396\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012849820777773857\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.16246573626995087\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0404660589993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07760897278785706\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09241589903831482\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.078804150223732\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014788930304348469\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.055386148393154144\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.08908805251121521\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.058421023190021515\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05153129622340202\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0394376777112484\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03952120617032051\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02768731862306595\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03526819497346878\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07492532581090927\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.053394995629787445\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025845013558864594\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02288699336349964\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01999017968773842\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030996965244412422\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010482213459908962\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06693306565284729\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12464753538370132\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02283661812543869\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014751451089978218\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022140473127365112\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07338777929544449\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019868794828653336\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020530883222818375\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03788210451602936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05054248869419098\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026042796671390533\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015149879269301891\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01724618300795555\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023125071078538895\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01614272966980934\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03588792681694031\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026546387001872063\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022355593740940094\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029102347791194916\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008131507784128189\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04581531882286072\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012310516089200974\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045934539288282394\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08279959112405777\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04281221330165863\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01904570870101452\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07480683922767639\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1133357584476471\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03068367950618267\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06669078022241592\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0062494659796357155\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.19306400418281555\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015313737094402313\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01129002682864666\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010909433476626873\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03835480287671089\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012454354204237461\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04181280732154846\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06144961714744568\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08094236254692078\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018081344664096832\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02908305823802948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03237168490886688\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030107757076621056\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07237202674150467\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06667662411928177\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0325918011367321\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02229631319642067\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022053377702832222\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02869337424635887\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04274453967809677\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01781442202627659\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04237271100282669\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08073964715003967\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.14124436676502228\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03271212428808212\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09349052608013153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05720464140176773\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02537459507584572\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027757609263062477\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014376407489180565\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06347866356372833\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02483964152634144\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026636984199285507\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04012053832411766\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019048582762479782\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03179750218987465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07338912785053253\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023195095360279083\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08706611394882202\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02931651845574379\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1449897736310959\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030844466760754585\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08018378168344498\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053226251155138016\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06223149225115776\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06929746270179749\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.052302245050668716\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018190981820225716\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013829345814883709\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01647534966468811\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06089060753583908\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020120756700634956\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07048671692609787\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04462393373250961\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.003150531090795994\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029302986338734627\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05177086964249611\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02836773544549942\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02731180563569069\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033567264676094055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008422024548053741\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02045050635933876\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03041442483663559\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06454846262931824\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022543884813785553\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032287415117025375\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.044981811195611954\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07209134846925735\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0558970645070076\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014914616011083126\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03366182744503021\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03814839571714401\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010711573995649815\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04429449886083603\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05418155714869499\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07569113373756409\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0180647075176239\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12589778006076813\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.12788937985897064\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014887447468936443\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04115845263004303\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019049836322665215\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.017605509608983994\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.15468260645866394\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024544883519411087\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029738198965787888\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03859541937708855\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08981627225875854\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.28206363320350647\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03481621667742729\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0246902909129858\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04117657616734505\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02847992442548275\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04949483275413513\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0140450494363904\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10073571652173996\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.004251588135957718\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015012477524578571\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06910072267055511\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047637589275836945\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059438638389110565\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025046084076166153\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04544931650161743\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026633867993950844\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08612353354692459\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.151310533285141\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05711861699819565\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06466870754957199\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.054771263152360916\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0901961401104927\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015171105973422527\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023771118372678757\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09050033241510391\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05846906453371048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029068395495414734\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10691282153129578\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04328853636980057\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.058650482445955276\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07894261181354523\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024514999240636826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028061341494321823\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.058995991945266724\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09755320847034454\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04531421139836311\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024471260607242584\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.15472909808158875\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018962401896715164\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04950757697224617\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01289861649274826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015577893704175949\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041222937405109406\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.019889649003744125\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03480590879917145\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06414780765771866\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0433354414999485\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.055919621139764786\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0928485170006752\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.11648835241794586\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06562891602516174\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05832042545080185\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10453484952449799\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12418490648269653\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013708493672311306\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09854719042778015\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1147226095199585\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0322466716170311\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021243255585432053\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08051159232854843\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04080796614289284\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05469514802098274\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028850262984633446\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06425777077674866\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013203451409935951\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010993260890245438\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.16821293532848358\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06636722385883331\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04954153299331665\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009689039550721645\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03773471713066101\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07700816541910172\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10534542053937912\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024373134598135948\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04010555148124695\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028362402692437172\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017831293866038322\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1352757215499878\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03132014349102974\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029262017458677292\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026678573340177536\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.026334241032600403\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0224099513143301\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07144810259342194\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03981573134660721\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03602152317762375\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018772264942526817\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09565134346485138\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017521090805530548\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03258915990591049\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05583367869257927\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008747204206883907\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09951718896627426\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02861596830189228\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02241794764995575\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010658351704478264\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0320240780711174\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0313752219080925\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05814963951706886\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04234347492456436\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019022854045033455\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05765152350068092\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04657227545976639\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06291952729225159\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.12200372666120529\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038202811032533646\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.10938992351293564\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02108452096581459\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07094232738018036\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01227635145187378\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011382421478629112\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06901423633098602\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0489971861243248\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012499435804784298\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05167563259601593\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030759179964661598\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.11183519661426544\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018861006945371628\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.054475001990795135\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020770739763975143\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.057061631232500076\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02058657817542553\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03610347956418991\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0996573343873024\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02977375127375126\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061337199062108994\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.047468360513448715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02744673192501068\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024305075407028198\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1153663918375969\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12774765491485596\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11257278174161911\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024719804525375366\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.056053515523672104\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1438813954591751\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040903761982917786\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02336777187883854\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03795816749334335\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11603741347789764\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.060363784432411194\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.053957097232341766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07686357945203781\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033049631863832474\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04426455497741699\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009786129929125309\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03813312202692032\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08638247847557068\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02020922675728798\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024881592020392418\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04651983827352524\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08022283017635345\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03280483931303024\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.020221156999468803\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011469059623777866\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1656612902879715\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0264144204556942\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019958708435297012\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.020550895482301712\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04727775603532791\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019448792561888695\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04715652018785477\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009835220873355865\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013962749391794205\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05861205980181694\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013991456478834152\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0415697917342186\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021485524252057076\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08273772895336151\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04139072448015213\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0578182153403759\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07580011337995529\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05022083595395088\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13026314973831177\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008595006540417671\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09961414337158203\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04741542041301727\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04592525213956833\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026361864060163498\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.045745715498924255\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009589044377207756\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015474418178200722\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03280644118785858\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015448878519237041\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06203717365860939\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03270471841096878\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12402525544166565\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013128034770488739\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04188184067606926\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.10837963223457336\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007101885974407196\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015795066952705383\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1175658255815506\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06887318193912506\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09893207252025604\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06905819475650787\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0946798324584961\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023284705355763435\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03007979691028595\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03220592811703682\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03268805146217346\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06518422812223434\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07228350639343262\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.020455647259950638\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03523530438542366\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07328914850950241\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057394832372665405\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04683441296219826\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023051394149661064\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011668902821838856\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1567164957523346\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0896512046456337\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018231168389320374\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07697898149490356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025821665301918983\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11544698476791382\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.2038038820028305\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017418095842003822\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06376709789037704\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04698535054922104\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0617503859102726\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019354339689016342\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06089681386947632\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.11154959350824356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02228127047419548\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10464673489332199\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014785772189497948\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.027594387531280518\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02440526708960533\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02598934806883335\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08567595481872559\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10856355726718903\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.08890453726053238\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07127463817596436\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04176776483654976\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11389279365539551\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.028807509690523148\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12336424738168716\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03509107604622841\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.061788637191057205\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.059121500700712204\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05941670387983322\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024789143353700638\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01381690800189972\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012706071138381958\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05690719932317734\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03218185901641846\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024706587195396423\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024106374010443687\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02110196463763714\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09898307919502258\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.041280217468738556\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048177607357501984\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.042489439249038696\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02425498515367508\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01794193871319294\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02330193668603897\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14151261746883392\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.046059057116508484\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0813131332397461\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04344434291124344\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.12161843478679657\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.05078680068254471\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04301008582115173\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11568869650363922\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04727798327803612\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.023185597732663155\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07978551089763641\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06897494196891785\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022904446348547935\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04473187029361725\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03331676125526428\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1326632797718048\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009028589352965355\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01707831397652626\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024380633607506752\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04990565404295921\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05091993883252144\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05485263094305992\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01330820843577385\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.043208152055740356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03204737603664398\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007007651496678591\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11163117736577988\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.20993119478225708\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018803270533680916\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08241152763366699\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02970353327691555\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04482918605208397\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019968044012784958\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019805800169706345\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035103939473629\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.037954557687044144\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.047872964292764664\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026809919625520706\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016077492386102676\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022510964423418045\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0875447615981102\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.17296704649925232\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033645253628492355\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0306454598903656\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05212864652276039\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02691442146897316\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.040062036365270615\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.019029337912797928\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010637969709932804\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021046914160251617\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.05848650261759758\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025545287877321243\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.13288384675979614\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0038914293982088566\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017942151054739952\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016875939443707466\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0395941399037838\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008094528689980507\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030161647126078606\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.13157407939434052\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.021128883585333824\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030794568359851837\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006431842688471079\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017751548439264297\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0677247941493988\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014697189442813396\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015173655934631824\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04678758606314659\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017840752378106117\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030006133019924164\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.043954357504844666\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05929633975028992\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.038366951048374176\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02831362746655941\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.018539369106292725\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05902502313256264\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.005248422734439373\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02362123318016529\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03188972920179367\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14763715863227844\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06511719524860382\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011046984232962132\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.1005568578839302\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025056518614292145\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01731325499713421\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05409161373972893\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022086644545197487\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030912362039089203\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1555808186531067\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019666308537125587\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015257597900927067\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.18232423067092896\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026463711634278297\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.057817988097667694\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016780298203229904\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015239119529724121\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04535757750272751\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013749362900853157\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02720264531672001\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0276082344353199\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019210085272789\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.007566217798739672\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.027226915583014488\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14504578709602356\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.044623807072639465\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02008064091205597\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1048082560300827\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.09331287443637848\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.029810108244419098\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028728002682328224\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04526541382074356\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014047706499695778\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.032838840037584305\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008231805637478828\n",
      "\n",
      "\n",
      "Training accuracy: 93.75\tTraining loss: 0.267488032579422\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03599858656525612\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.006119889207184315\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0897989571094513\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09602650254964828\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04340272396802902\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06717684119939804\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03822135925292969\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05770963430404663\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.023572567850351334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.045672573149204254\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08019233494997025\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1294102817773819\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08137160539627075\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.026605434715747833\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02429778128862381\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024835865944623947\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06086724251508713\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0612713098526001\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.035667672753334045\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03771305829286575\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05698492005467415\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03719668090343475\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08214942365884781\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019182033836841583\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012206142768263817\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014865407720208168\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.05683384835720062\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.033869847655296326\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.059357792139053345\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04072203487157822\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0566968210041523\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06175880879163742\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030124248936772346\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1301438808441162\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07791919261217117\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.024160783737897873\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013333000242710114\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.048251740634441376\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.029403971508145332\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.045010246336460114\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.017212312668561935\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02091514691710472\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03629496693611145\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01805249974131584\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039614349603652954\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02325727976858616\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.028813568875193596\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012741819955408573\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06985972821712494\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015208394266664982\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.044040780514478683\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.003518956946209073\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04205799847841263\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13637393712997437\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011143367737531662\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015536640770733356\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05233868956565857\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17656764388084412\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.030368000268936157\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019702285528182983\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02935524471104145\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013568632304668427\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.1266569346189499\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.07851488888263702\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.04772242531180382\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03385266661643982\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07922455668449402\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.12075704336166382\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04761319234967232\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.02951868623495102\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016753943637013435\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.049941010773181915\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.014697864651679993\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.052093975245952606\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08891241252422333\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01364090945571661\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.14437228441238403\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012851756997406483\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08650703728199005\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.039061762392520905\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13505251705646515\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0650099366903305\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04799259826540947\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0929710641503334\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0451359823346138\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04143678396940231\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.019141115248203278\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06179051101207733\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0197148397564888\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07634662091732025\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.009100266732275486\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.0313139371573925\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.21160103380680084\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.022731460630893707\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008383375592529774\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05208013206720352\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.011771495454013348\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04253121092915535\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09222632646560669\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.030532799661159515\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010528972372412682\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.033468909561634064\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.1208881139755249\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01767130009829998\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.09134701639413834\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.11651436239480972\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03503529727458954\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.031412526965141296\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04097525775432587\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.03754846751689911\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07459640502929688\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008288352750241756\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03459300845861435\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07063048332929611\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.10639984160661697\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06355715543031693\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.06466594338417053\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01899910904467106\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032912470400333405\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.047360438853502274\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06683212518692017\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.025353997945785522\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.06397860497236252\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03407840058207512\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.03681568801403046\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.024353152140975\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.14253638684749603\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010959208011627197\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.025794390588998795\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02162255346775055\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016254417598247528\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.17394234240055084\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.1281086653470993\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013168512843549252\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04245422035455704\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.10629850625991821\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08934792876243591\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.015358228236436844\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04236321896314621\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01820286549627781\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07404346764087677\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09543970972299576\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02693992108106613\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13190986216068268\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.07293549925088882\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.010742029175162315\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.013807016424834728\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03366972506046295\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.09225654602050781\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.04824342578649521\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.16009733080863953\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.13777242600917816\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.012945649214088917\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.02234516106545925\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.07404899597167969\n",
      "\n",
      "\n",
      "Training accuracy: 95.31\tTraining loss: 0.08140557259321213\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.045431558042764664\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.0425981841981411\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.0190722718834877\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.016526635736227036\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.036404531449079514\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.06179448217153549\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03985542804002762\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05556243285536766\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04218699410557747\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.008347228169441223\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.08665864169597626\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.03494708612561226\n",
      "\n",
      "\n",
      "Training accuracy: 96.88\tTraining loss: 0.05860118567943573\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.032872989773750305\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.036991335451602936\n",
      "\n",
      "\n",
      "Training accuracy: 98.44\tTraining loss: 0.04849035665392876\n",
      "\n",
      "\n",
      "Training accuracy: 100.0\tTraining loss: 0.01188755128532648\n",
      "\n",
      "\n",
      "Validation accuracy: 97.37\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(net, nn.CrossEntropyLoss, optim.Adam, training_data, test_data)\n",
    "\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    print(f\"Epoch {i+1}..\")\n",
    "    trainer.train()\n",
    "    trainer.validate()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c86d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efbd25c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\", weights_only=True, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "583bc1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "inputs, targets = next(iter(train_loader))\n",
    "\n",
    "input = inputs[0].squeeze(1).flatten(1, 2)\n",
    "input = input.to(device)\n",
    "input.requires_grad_()\n",
    "\n",
    "target = targets[0]\n",
    "target = target.to(device)\n",
    "\n",
    "output = model(input).squeeze()\n",
    "\n",
    "loss = F.cross_entropy(output, target)\n",
    "loss.backward()\n",
    "\n",
    "epsilon = 0.04\n",
    "perturbed = input + epsilon * input.grad.sign()\n",
    "\n",
    "perturbed = perturbed.unflatten(1, (28, 28))\n",
    "input = input.unflatten(1, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dedaa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n",
      "Actual: 3\n",
      "\n",
      "Correct? False\n"
     ]
    }
   ],
   "source": [
    "perturbed_output = model(perturbed.squeeze().flatten()).argmax().item()\n",
    "correct = target == perturbed_output\n",
    "\n",
    "show(perturbed)\n",
    "print(f\"Prediction: {perturbed_output}\\nActual: {target}\\n\\nCorrect? {correct}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
